import warnings
import numpy as np
import pandas as pd
from catboost import CatBoostRegressor
from lightgbm import LGBMRegressor
from xgboost import XGBRegressor
from sklearn.cluster import KMeans 
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.model_selection import TimeSeriesSplit
from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model import Ridge

warnings.filterwarnings("ignore")

# -----------------------------
# 0) Load
# -----------------------------
train = pd.read_csv("./data/train_.csv")
test = pd.read_csv("./data/test_.csv")

# -----------------------------
# 1) ì „ì—­ ìƒìˆ˜ ì •ì˜
# -----------------------------
REF_DATE = pd.Timestamp("2024-10-24")

MAX_PRICE = 1.0
MID_PRICE = 0.6
LIGHT_PRICE = 0.4

# -----------------------------
# 1.5) ì‹œê°„ íŒŒìƒ ë° TOU ì¸ì½”ë”©
# -----------------------------
def adjust_hour(dt):
    if pd.isna(dt): return np.nan
    return (dt.hour - 1) % 24 if dt.minute == 0 else dt.hour

def get_tou_relative_price(m, h, period_flag):
    if period_flag == 1: 
        if m in [7, 8]:
            if (10 <= h < 12) or (13 <= h < 17): return MAX_PRICE
            if (9 <= h < 10) or (12 <= h < 13) or (17 <= h < 22): return MID_PRICE
            return LIGHT_PRICE
        elif m in [12, 1, 2]:
            if (9 <= h < 12) or (17 <= h < 22): return MAX_PRICE
            if (12 <= h < 17) or (22 <= h < 23): return MID_PRICE
            return LIGHT_PRICE
        else:
            if (9 <= h < 23): return MID_PRICE
            return LIGHT_PRICE
    else:
        if m in [7, 8]:
            if (10 <= h < 12) or (13 <= h < 17): return MAX_PRICE
            if (9 <= h < 10) or (12 <= h < 13) or (17 <= h < 22): return MID_PRICE
            return LIGHT_PRICE
        elif m in [12, 1, 2]:
            if (9 <= h < 12) or (17 <= h < 22): return MAX_PRICE
            if (12 <= h < 17) or (22 <= h < 23): return MID_PRICE
            return LIGHT_PRICE
        else:
            if (9 <= h < 23): return MID_PRICE
            return LIGHT_PRICE

def enrich(df):
    df["ì¸¡ì •ì¼ì‹œ"] = pd.to_datetime(df["ì¸¡ì •ì¼ì‹œ"], errors="coerce")
    df["ì›”"] = df["ì¸¡ì •ì¼ì‹œ"].dt.month
    df["ì¼"] = df["ì¸¡ì •ì¼ì‹œ"].dt.day
    df["ìš”ì¼"] = df["ì¸¡ì •ì¼ì‹œ"].dt.dayofweek
    df["ë‚ ì§œ"] = df['ì¸¡ì •ì¼ì‹œ'].dt.date 
    df["ì‹œê°„"] = df["ì¸¡ì •ì¼ì‹œ"].apply(adjust_hour)
    df["ì£¼ë§ì—¬ë¶€"] = (df["ìš”ì¼"] >= 5).astype(int)
    df["ê²¨ìš¸ì—¬ë¶€"] = df["ì›”"].isin([11, 12, 1, 2]).astype(int) 
    df["period_flag"] = (df["ì¸¡ì •ì¼ì‹œ"] >= REF_DATE).astype(int)
    
    df["sin_time"] = np.sin(2 * np.pi * df["ì‹œê°„"] / 24)
    df["cos_time"] = np.cos(2 * np.pi * df["ì‹œê°„"] / 24)
    
    df["tou_relative_price"] = df.apply(lambda row: get_tou_relative_price(row["ì›”"], row["ì‹œê°„"], row["period_flag"]), axis=1)
    
    df["tou_load_index"] = df.apply(lambda row: 3 if row["tou_relative_price"] == MAX_PRICE else (2 if row["tou_relative_price"] == MID_PRICE else 1), axis=1)
    df["tou_price_code"] = df["period_flag"].astype(str) + "_" + df["tou_load_index"].astype(str)
    
    df["sin_day"] = np.sin(2 * np.pi * df["ì¼"] / 31)
    df["cos_day"] = np.cos(2 * np.pi * df["ì¼"] / 31)
    df["sin_month"] = np.sin(2 * np.pi * df["ì›”"] / 12)
    df["cos_month"] = np.cos(2 * np.pi * df["ì›”"] / 12)
    return df

train = enrich(train).sort_values("ì¸¡ì •ì¼ì‹œ").reset_index(drop=True)
test = enrich(test).sort_values("ì¸¡ì •ì¼ì‹œ").reset_index(drop=True)

# -----------------------------
# 2) ì¸ì½”ë”©
# -----------------------------
le_job = LabelEncoder()
train["ì‘ì—…ìœ í˜•_encoded"] = le_job.fit_transform(train["ì‘ì—…ìœ í˜•"].astype(str))
def safe_transform(le, series, mode_val):
    series_mapped = series.astype(str).map(lambda s: '-1' if s not in le.classes_ else s)
    return le.transform(series_mapped.replace('-1', mode_val))

test["ì‘ì—…ìœ í˜•_encoded"] = safe_transform(le_job, test["ì‘ì—…ìœ í˜•"], train["ì‘ì—…ìœ í˜•"].mode()[0])

le_tou = LabelEncoder()
train["tou_price_code_encoded"] = le_tou.fit_transform(train["tou_price_code"].astype(str))
test["tou_price_code_encoded"] = safe_transform(le_tou, test["tou_price_code"], train["tou_price_code"].mode()[0])

train["ì‹œê°„_ì‘ì—…ìœ í˜•"] = train["ì‹œê°„"].astype(str) + "_" + train["ì‘ì—…ìœ í˜•_encoded"].astype(str)
test["ì‹œê°„_ì‘ì—…ìœ í˜•"] = test["ì‹œê°„"].astype(str) + "_" + test["ì‘ì—…ìœ í˜•_encoded"].astype(str)
le_tj = LabelEncoder()
train["ì‹œê°„_ì‘ì—…ìœ í˜•_encoded"] = le_tj.fit_transform(train["ì‹œê°„_ì‘ì—…ìœ í˜•"])
test["ì‹œê°„_ì‘ì—…ìœ í˜•_encoded"] = safe_transform(le_tj, test["ì‹œê°„_ì‘ì—…ìœ í˜•"], train["ì‹œê°„_ì‘ì—…ìœ í˜•"].mode()[0])

# -----------------------------
# 2.5) ğŸ”¥ ë‹¨ìˆœí™”ëœ ìˆ˜ìš”ìš”ê¸ˆ ê³„ì‚° (ë²¡í„°í™”)
# -----------------------------
def calculate_demand_charge_simple(df):
    """ë‹¨ìˆœí•˜ê³  ë¹ ë¥¸ ìˆ˜ìš”ìš”ê¸ˆ ê³„ì‚°"""
    df = df.sort_values('ì¸¡ì •ì¼ì‹œ').copy()
    df["í”¼ìƒì „ë ¥_sim"] = np.sqrt(df["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"]**2 + df["ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)"]**2)
    
    # ê³„ì ˆë³„ í”¼í¬ë§Œ ê³ ë ¤
    demand_months = [7, 8, 9, 12, 1, 2]
    df['is_demand_season'] = df['ì›”'].isin(demand_months).astype(int)
    
    # ìµœê·¼ 365ì¼ í”¼í¬ (ê°„ë‹¨í•œ rolling)
    df['ìš”ê¸ˆì ìš©ì „ë ¥_kW_true'] = (
        df['í”¼ìƒì „ë ¥_sim']
        .rolling(window=min(8760, len(df)), min_periods=1)
        .max()
    )
    
    return df

print("\nğŸ”„ ìˆ˜ìš”ìš”ê¸ˆ ê³„ì‚° ì¤‘...")
train = calculate_demand_charge_simple(train)

# -----------------------------
# 3) Stage1: ì „ë ¥íŠ¹ì„± ì˜ˆì¸¡
# -----------------------------
targets_s1 = ["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)", "ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)", "ì§„ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)", 
              "ì§€ìƒì—­ë¥ (%)", "ì§„ìƒì—­ë¥ (%)", "ìš”ê¸ˆì ìš©ì „ë ¥_kW_true"]

feat_s1 = ["ì›”","ì¼","ìš”ì¼","ì‹œê°„","ì£¼ë§ì—¬ë¶€","ê²¨ìš¸ì—¬ë¶€","period_flag",
           "sin_time","cos_time","sin_day", "cos_day", "sin_month", "cos_month",
           "ì‘ì—…ìœ í˜•_encoded", "tou_relative_price", "tou_price_code_encoded", "ì‹œê°„_ì‘ì—…ìœ í˜•_encoded"] 

# ğŸ”¥ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì›ë³µ (ê³¼ì í•© ë°©ì§€)
stage1_models = {
    "ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)": LGBMRegressor(n_estimators=2000, learning_rate=0.015, num_leaves=96, random_state=42),
    "ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)": CatBoostRegressor(iterations=1500, learning_rate=0.05, depth=6, verbose=0, random_seed=42),
    "ì§„ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)": CatBoostRegressor(iterations=1500, learning_rate=0.05, depth=6, verbose=0, random_seed=42),
    "ì§€ìƒì—­ë¥ (%)": LGBMRegressor(n_estimators=1500, learning_rate=0.03, num_leaves=64, random_state=42),
    "ì§„ìƒì—­ë¥ (%)": LGBMRegressor(n_estimators=1500, learning_rate=0.03, num_leaves=64, random_state=42),
    "ìš”ê¸ˆì ìš©ì „ë ¥_kW_true": LGBMRegressor(n_estimators=2000, learning_rate=0.02, num_leaves=48, random_state=42),
}

tscv = TimeSeriesSplit(n_splits=5)
stage1_oof = pd.DataFrame(index=train.index)
stage1_test_pred = pd.DataFrame(index=test.index)
train_targets_true = train[targets_s1].copy()

print("\nğŸš€ Stage 1: ì „ë ¥íŠ¹ì„± ì˜ˆì¸¡ ì‹œì‘...")
for tgt in targets_s1:
    print(f"  í•™ìŠµ ì¤‘: {tgt}")
    oof_pred = np.full(len(train), np.nan, dtype=float)
    model = stage1_models[tgt]
    
    current_target = train_targets_true[tgt].copy()
    is_demand_target = (tgt == "ìš”ê¸ˆì ìš©ì „ë ¥_kW_true")
    if is_demand_target:
        current_target = np.log1p(current_target)

    for fold, (tr_idx, va_idx) in enumerate(tscv.split(train), start=1):
        fold_model = model.__class__(**model.get_params())
        fold_model.fit(train.iloc[tr_idx][feat_s1], current_target.iloc[tr_idx])
        oof_pred[va_idx] = fold_model.predict(train.iloc[va_idx][feat_s1])

    missing = np.isnan(oof_pred)
    if missing.any():
        full_model = model.__class__(**model.get_params())
        full_model.fit(train[feat_s1], current_target)
        oof_pred[missing] = full_model.predict(train.loc[missing, feat_s1])
        
    if is_demand_target:
        oof_pred = np.expm1(oof_pred).clip(min=0)

    stage1_oof[tgt] = oof_pred
    
    final_model = model.__class__(**model.get_params())
    final_model.fit(train[feat_s1], current_target)
    test_pred = final_model.predict(test[feat_s1])
    
    if is_demand_target:
        test_pred = np.expm1(test_pred).clip(min=0)
        
    stage1_test_pred[tgt] = test_pred

for tgt in targets_s1:
    new_col_name = "ìš”ê¸ˆì ìš©ì „ë ¥_kW" if tgt == "ìš”ê¸ˆì ìš©ì „ë ¥_kW_true" else tgt
    train[new_col_name] = stage1_oof[tgt]
    test[new_col_name] = stage1_test_pred[tgt]
    
train["í”¼ìƒì „ë ¥_sim"] = np.sqrt(train["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"]**2 + train["ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)"]**2)
test["í”¼ìƒì „ë ¥_sim"] = np.sqrt(test["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"]**2 + test["ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)"]**2)

print("âœ… Stage 1 ì™„ë£Œ")

# -----------------------------
# 3.5) Stage1 í›„ì²˜ë¦¬
# -----------------------------
def post_process_stage1(df):
    P = df["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"]
    Q = df["ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)"]
    
    safe_denominator = np.sqrt(P**2 + Q**2) + 1e-6
    df["PF_recalc"] = 100 * P / safe_denominator
    df["PF_recalc"] = df["PF_recalc"].clip(upper=100.0) 
    
    df["PF_diff"] = df["PF_recalc"] - df["ì§€ìƒì—­ë¥ (%)"]
    
    is_low_kwh = (df["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"] < 0.5)
    df["PF_recalc"] = np.where(is_low_kwh, 95.0, df["PF_recalc"])
    df["PF_diff"] = np.where(is_low_kwh, 0.0, df["PF_diff"])
    
    return df

train = post_process_stage1(train)
test = post_process_stage1(test)

# -----------------------------
# 4) ì—­ë¥  ê·œì • í”¼ì²˜
# -----------------------------
def add_pf_features_regulated(df):
    df["ìœ íš¨ì—­ë¥ (%)"] = df[["ì§€ìƒì—­ë¥ (%)", "ì§„ìƒì—­ë¥ (%)"]].max(axis=1)
    df["ì—­ë¥ _íŒ¨ë„í‹°ìœ¨"] = (90 - df["ìœ íš¨ì—­ë¥ (%)"]).clip(lower=0) * 0.01
    df["ì—­ë¥ _ë³´ìƒìœ¨"] = (df["ìœ íš¨ì—­ë¥ (%)"] - 90).clip(lower=0) * 0.005
    df["ì—­ë¥ _ì¡°ì •ìš”ìœ¨"] = df["ì—­ë¥ _ë³´ìƒìœ¨"] - df["ì—­ë¥ _íŒ¨ë„í‹°ìœ¨"]
    
    df["ì£¼ê°„ì—¬ë¶€"] = df["ì‹œê°„"].isin(range(9, 23)).astype(int)
    df["ì§€ìƒì—­ë¥ _ë³´ì •"] = df["PF_recalc"].clip(lower=60)
    df["ì§€ìƒì—­ë¥ _ì£¼ê°„í´ë¦½"] = np.where(df["ì£¼ê°„ì—¬ë¶€"] == 1, 
                                    df["ì§€ìƒì—­ë¥ _ë³´ì •"].clip(upper=95), 
                                    df["ì§€ìƒì—­ë¥ _ë³´ì •"])
    
    df["ì—­ë¥ ë¶€ì¡±í­_94"] = (94 - df["ì§€ìƒì—­ë¥ _ì£¼ê°„í´ë¦½"]).clip(lower=0) * df["ì£¼ê°„ì—¬ë¶€"]
    df["ì—­ë¥ ë¶€ì¡±í­_90"] = (90 - df["ì§€ìƒì—­ë¥ _ì£¼ê°„í´ë¦½"]).clip(lower=0) * df["ì£¼ê°„ì—¬ë¶€"]
    df["ì—­ë¥ ìš°ìˆ˜"] = (df["ì§€ìƒì—­ë¥ _ì£¼ê°„í´ë¦½"] >= 95).astype(int) 
    
    df["ë²•ì í˜ë„í‹°"] = ((df["ì§€ìƒì—­ë¥ _ì£¼ê°„í´ë¦½"] < 90) & (df["ì£¼ê°„ì—¬ë¶€"] == 1)).astype(int)
    df["ì‹¤ì§ˆìœ„í—˜"] = ((df["ì§€ìƒì—­ë¥ _ì£¼ê°„í´ë¦½"] < 94) & (df["ì£¼ê°„ì—¬ë¶€"] == 1)).astype(int)
    
    return df

train = add_pf_features_regulated(train)
test = add_pf_features_regulated(test)

# -----------------------------
# 5) ğŸ”¥ í•µì‹¬ êµì°¨í•­ë§Œ ì¶”ê°€
# -----------------------------
def add_critical_interactions(df):
    # TOU Ã— ì—­ë¥ ë¶€ì¡±
    df['tou_pf_risk'] = df['tou_relative_price'] * df['ì—­ë¥ ë¶€ì¡±í­_94']
    
    # ìœ„í—˜ êµ¬ê°„
    df['critical_zone'] = (
        (df['tou_relative_price'] == MAX_PRICE) & 
        (df['PF_recalc'] >= 90) & 
        (df['PF_recalc'] < 94)
    ).astype(int)
    
    # ì „ë ¥ Ã— ì—­ë¥ 
    df["ë¶€í•˜ì—­ë¥ ê³±"] = df["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"] * df["ì—­ë¥ ë¶€ì¡±í­_94"]
    
    return df

train = add_critical_interactions(train)
test = add_critical_interactions(test)

# -----------------------------
# 6) Lag/Rolling
# -----------------------------
def add_lag_roll(df, hist_data, is_train=True):
    df["kwh_lag1"] = df["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"].shift(1)
    df["kwh_lag24"] = df["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"].shift(24)
    df["kwh_roll24_mean"] = df["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"].shift(1).rolling(24).mean()
    df["kwh_roll24_std"] = df["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"].shift(1).rolling(24).std().fillna(0)
    
    if is_train:
        df.fillna(method='bfill', inplace=True)
        return df.fillna(0)
    else: 
        hist_data_kwh = list(hist_data["kwh"].values.astype(float))
        
        for i in range(len(df)):
            df.loc[df.index[i], "kwh_lag1"] = hist_data_kwh[-1] if len(hist_data_kwh) >= 1 else 0
            df.loc[df.index[i], "kwh_lag24"] = hist_data_kwh[-24] if len(hist_data_kwh) >= 24 else 0
            arr24 = np.array(hist_data_kwh[-24:])
            df.loc[df.index[i], "kwh_roll24_mean"] = arr24.mean() if arr24.size > 0 else 0
            df.loc[df.index[i], "kwh_roll24_std"] = arr24.std() if arr24.size > 1 else 0
            
            hist_data_kwh.append(df.loc[df.index[i], "ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"])
            
        return df

hist_data_train = {"kwh": train["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"]}
hist_data_test = {"kwh": train["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"].copy()}

train = add_lag_roll(train, hist_data_train, is_train=True)
test = add_lag_roll(test, hist_data_test, is_train=False)

# -----------------------------
# 7) ê³ ê¸‰ í”¼ì²˜
# -----------------------------
kwh_mean_day_hour = train.groupby(["ìš”ì¼", "ì‹œê°„"])["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"].mean().reset_index()
kwh_mean_day_hour.rename(columns={"ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)": "kwh_ìš”ì¼_ì‹œê°„_í‰ê· "}, inplace=True)
train = pd.merge(train, kwh_mean_day_hour, on=["ìš”ì¼", "ì‹œê°„"], how="left")
test = pd.merge(test, kwh_mean_day_hour, on=["ìš”ì¼", "ì‹œê°„"], how="left")

def add_advanced_features(df, train_means=None):
    df["ë¬´íš¨ìœ íš¨ë¹„ìœ¨"] = df["ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)"] / (df["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"] + 1e-6)
    df["ì—­ë¥ ë‹¹ì „ë ¥"] = df["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"] / (df["ì§€ìƒì—­ë¥ _ì£¼ê°„í´ë¦½"] + 1e-6) 

    if train_means: 
        df["ì—­ë¥ _ì›”í‰ê· "] = df["ì›”"].map(train_means["ì—­ë¥ _ì›”í‰ê· "])
        df["ì—­ë¥ _ì›”í‰ê· "].fillna(train_means["ì—­ë¥ _ì›”í‰ê· "].mean(), inplace=True) 
    else: 
        df["ì—­ë¥ _ì›”í‰ê· "] = df.groupby("ì›”")["ì§€ìƒì—­ë¥ _ì£¼ê°„í´ë¦½"].transform("mean")

    df["ì—­ë¥ _ì›”í‰ê· ì°¨ì´"] = df["ì§€ìƒì—­ë¥ _ì£¼ê°„í´ë¦½"] - df["ì—­ë¥ _ì›”í‰ê· "]
    df["kwh_roll24_cv"] = df["kwh_roll24_std"] / (df["kwh_roll24_mean"] + 1e-6)
    df["kwh_ë³€í™”ìœ¨_24h"] = ((df["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"] - df["kwh_lag24"]) / (df["kwh_lag24"] + 1e-6))
    
    df["kwh_ì‹œê°„ëŒ€ë¹„_ìš”ì¼"] = df["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"] / (df["kwh_ìš”ì¼_ì‹œê°„_í‰ê· "] + 1e-6)
    df.drop("kwh_ìš”ì¼_ì‹œê°„_í‰ê· ", axis=1, inplace=True)
    
    df["ì´ë¬´íš¨ì „ë ¥"] = df["ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)"] + df["ì§„ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)"]
    
    return df

train_means_for_test = {"ì—­ë¥ _ì›”í‰ê· ": train.groupby("ì›”")["ì§€ìƒì—­ë¥ _ì£¼ê°„í´ë¦½"].mean()}
train = add_advanced_features(train)
test = add_advanced_features(test, train_means=train_means_for_test)

# -----------------------------
# 8) ì¼ì¼ íŒ¨í„´
# -----------------------------
print("\nğŸ”„ ì¼ì¼ ì „ë ¥ ì‚¬ìš© íŒ¨í„´ í”¼ì²˜ ìƒì„± ì¤‘...")
train_pattern_pivot = train.pivot_table(index='ë‚ ì§œ', columns='ì‹œê°„', values='ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)')
train_pattern_pivot = train_pattern_pivot.fillna(train_pattern_pivot.mean().mean())

kmeans = KMeans(n_clusters=3, random_state=42, n_init='auto')
train_pattern_pivot['ì¼ì¼íŒ¨í„´ìœ í˜•'] = kmeans.fit_predict(train_pattern_pivot)
pattern_map = train_pattern_pivot[['ì¼ì¼íŒ¨í„´ìœ í˜•']].reset_index()
train = pd.merge(train, pattern_map, on='ë‚ ì§œ', how='left')

test_pattern_pivot = test.pivot_table(index='ë‚ ì§œ', columns='ì‹œê°„', values='ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)')
test_pattern_pivot = test_pattern_pivot.fillna(train_pattern_pivot.drop('ì¼ì¼íŒ¨í„´ìœ í˜•', axis=1).mean().mean())
train_cols_no_target = train_pattern_pivot.drop(columns='ì¼ì¼íŒ¨í„´ìœ í˜•').columns
test_pattern_pivot = test_pattern_pivot.reindex(columns=train_cols_no_target, fill_value=train_pattern_pivot.drop('ì¼ì¼íŒ¨í„´ìœ í˜•', axis=1).mean().mean())
test_pattern_pivot['ì¼ì¼íŒ¨í„´ìœ í˜•'] = kmeans.predict(test_pattern_pivot[train_cols_no_target])
test_pattern_map = test_pattern_pivot[['ì¼ì¼íŒ¨í„´ìœ í˜•']].reset_index()
test = pd.merge(test, test_pattern_map, on='ë‚ ì§œ', how='left')

most_frequent_pattern = train['ì¼ì¼íŒ¨í„´ìœ í˜•'].mode()[0]
train['ì¼ì¼íŒ¨í„´ìœ í˜•'].fillna(most_frequent_pattern, inplace=True)
test['ì¼ì¼íŒ¨í„´ìœ í˜•'].fillna(most_frequent_pattern, inplace=True)
train['ì¼ì¼íŒ¨í„´ìœ í˜•'] = train['ì¼ì¼íŒ¨í„´ìœ í˜•'].astype(int)
test['ì¼ì¼íŒ¨í„´ìœ í˜•'] = test['ì¼ì¼íŒ¨í„´ìœ í˜•'].astype(int)

# -----------------------------
# 9) ğŸ”¥ Stage2 Feature Set (ìµœì†Œí™”)
# -----------------------------
feat_s2 = [
    "ì›”","ì¼","ìš”ì¼","ì‹œê°„","ì£¼ë§ì—¬ë¶€","ê²¨ìš¸ì—¬ë¶€","period_flag",
    "sin_time","cos_time","sin_day", "cos_day", "sin_month", "cos_month",
    "ì‘ì—…ìœ í˜•_encoded", "tou_relative_price", "tou_price_code_encoded", "ì‹œê°„_ì‘ì—…ìœ í˜•_encoded",
    "ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)","ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)","ì§„ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)",
    "ì§€ìƒì—­ë¥ (%)","ì§„ìƒì—­ë¥ (%)",
    "ìœ íš¨ì—­ë¥ (%)","ì—­ë¥ _ì¡°ì •ìš”ìœ¨",
    "ì§€ìƒì—­ë¥ _ë³´ì •", "ì§€ìƒì—­ë¥ _ì£¼ê°„í´ë¦½", "ì£¼ê°„ì—¬ë¶€", 
    "ë²•ì í˜ë„í‹°","ì‹¤ì§ˆìœ„í—˜","ì—­ë¥ ë¶€ì¡±í­_94", "ì—­ë¥ ë¶€ì¡±í­_90", "ì—­ë¥ ìš°ìˆ˜",
    "ì´ë¬´íš¨ì „ë ¥", 
    "PF_recalc", "PF_diff", 
    "ë¬´íš¨ìœ íš¨ë¹„ìœ¨","ë¶€í•˜ì—­ë¥ ê³±", "ì—­ë¥ ë‹¹ì „ë ¥",
    "ì—­ë¥ _ì›”í‰ê· ","ì—­ë¥ _ì›”í‰ê· ì°¨ì´",
    "kwh_roll24_cv","kwh_ë³€í™”ìœ¨_24h",
    "kwh_lag1","kwh_lag24","kwh_roll24_mean","kwh_roll24_std",
    "kwh_ì‹œê°„ëŒ€ë¹„_ìš”ì¼", 
    "ìš”ê¸ˆì ìš©ì „ë ¥_kW", "í”¼ìƒì „ë ¥_sim", 
    "tou_pf_risk", "critical_zone",
    "ì¼ì¼íŒ¨í„´ìœ í˜•" 
]

print(f"\nğŸ’¡ Stage 2 í”¼ì²˜ ê°œìˆ˜: {len(feat_s2)}")

# -----------------------------
# 10) ğŸ”¥ Stage2 í•™ìŠµ (ë³´ìˆ˜ì  í•˜ì´í¼íŒŒë¼ë¯¸í„°)
# -----------------------------
X_all = train[feat_s2].copy()
y_all = train["ì „ê¸°ìš”ê¸ˆ(ì›)"].copy()
y_all_log = np.log1p(y_all)
X_te = test[feat_s2].copy()

# ğŸ”¥ í•˜ì´í¼íŒŒë¼ë¯¸í„° ë³´ìˆ˜ì ìœ¼ë¡œ ì¡°ì • (ê³¼ì í•© ë°©ì§€)
LGB_PARAMS = dict(n_estimators=3000, learning_rate=0.015, num_leaves=64, 
                  subsample=0.85, colsample_bytree=0.85, 
                  reg_alpha=3, reg_lambda=3, random_state=42, n_jobs=-1)
XGB_PARAMS = dict(n_estimators=3000, learning_rate=0.015, max_depth=6, 
                  subsample=0.85, colsample_bytree=0.85, 
                  reg_lambda=3, reg_alpha=2, random_state=42, n_jobs=-1)
CAT_PARAMS = dict(iterations=2500, learning_rate=0.02, depth=7, 
                  l2_leaf_reg=5, random_seed=42, verbose=0, thread_count=-1)

base_models = {
    "lgb": LGBMRegressor(**LGB_PARAMS),
    "xgb": XGBRegressor(**XGB_PARAMS),
    "cat": CatBoostRegressor(**CAT_PARAMS)
}

# ğŸ”¥ Meta-Learner ë‹¨ìˆœí™” (Ridge)
meta_learner = Ridge(alpha=10.0)
tscv_s2 = TimeSeriesSplit(n_splits=5)

oof_preds_s2 = pd.DataFrame(index=X_all.index, columns=base_models.keys(), dtype=float)
test_preds_s2 = np.zeros((len(X_te), len(base_models)))

print("\nğŸš€ Stage 2 ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
for fold, (tr_idx, va_idx) in enumerate(tscv_s2.split(X_all), start=1):
    print(f"--- Fold {fold} ---")
    X_tr, X_va = X_all.iloc[tr_idx], X_all.iloc[va_idx]
    y_tr_log = y_all_log.iloc[tr_idx]

    fold_test_preds = [] 

    for name, model in base_models.items():
        print(f"  Training {name}...")
        fold_model = model.__class__(**model.get_params())
        fold_model.fit(X_tr, y_tr_log)

        oof_pred = fold_model.predict(X_va)
        oof_preds_s2.iloc[va_idx, list(base_models.keys()).index(name)] = oof_pred

        fold_test_preds.append(fold_model.predict(X_te))

    test_preds_s2 += np.column_stack(fold_test_preds) / tscv_s2.n_splits

print("\nâœ… OOF ì˜ˆì¸¡ ìƒì„± ì™„ë£Œ.")

# Meta-Learner í•™ìŠµ 
oof_valid_idx = oof_preds_s2.dropna().index
print(f"\nğŸ§  Meta-Learner í•™ìŠµ ì‹œì‘...")
meta_learner.fit(oof_preds_s2.loc[oof_valid_idx], y_all_log.loc[oof_valid_idx])

# ìµœì¢… Test ì˜ˆì¸¡
meta_test_input = pd.DataFrame(test_preds_s2, columns=base_models.keys(), index=X_te.index)
pred_te_log = meta_learner.predict(meta_test_input)
pred_te = np.expm1(pred_te_log)

# OOF ê²€ì¦
oof_pred_final_log = meta_learner.predict(oof_preds_s2.loc[oof_valid_idx])
oof_pred_final = np.expm1(oof_pred_final_log)
oof_mae = mean_absolute_error(y_all.loc[oof_valid_idx], oof_pred_final)
oof_r2 = r2_score(y_all.loc[oof_valid_idx], oof_pred_final)
print(f"\nğŸ“Š OOF ê²€ì¦: MAE={oof_mae:.2f} | RÂ²={oof_r2:.4f}")

# ì›”ë³„ MAE
oof_valid_months = train.loc[oof_valid_idx, "ì›”"]
monthly_mae = {}
for month in sorted(oof_valid_months.dropna().unique()):
    month_index = oof_valid_months.index[oof_valid_months == month]
    if len(month_index) == 0:
        continue
    month_mae = mean_absolute_error(y_all.loc[month_index], oof_pred_final[oof_valid_months == month])
    monthly_mae[int(month)] = month_mae

if monthly_mae:
    print("\nğŸ“† ì›”ë³„ OOF MAE:")
    for month in sorted(monthly_mae):
        print(f"  {month}ì›” MAE={monthly_mae[month]:.2f}")

# -----------------------------
# 11) ğŸ”¥ ë³´ìˆ˜ì  í›„ì²˜ë¦¬ (Train ë¶„í¬ ìœ ì§€)
# -----------------------------
print("\nğŸ”§ í›„ì²˜ë¦¬ ì ìš© ì¤‘...")

# Trainì˜ ì‹¤ì œ ë¶„í¬ ê¸°ë°˜
train_p01 = np.percentile(y_all, 0.5)
train_p99 = np.percentile(y_all, 99.5)
train_mean = y_all.mean()
train_std = y_all.std()

print(f"Train í†µê³„: í‰ê· ={train_mean:.2f}, í‘œì¤€í¸ì°¨={train_std:.2f}")
print(f"Train ë²”ìœ„: {y_all.min():.2f} ~ {y_all.max():.2f}")

# ğŸ”¥ ê·¹ë‹¨ê°’ë§Œ ë¶€ë“œëŸ½ê²Œ ì¡°ì •
pred_te_adjusted = pred_te.copy()

# í•˜í•œì„ : 0.5 percentile ê¸°ì¤€
lower_bound = max(0, train_p01 * 0.8)
pred_te_adjusted = np.where(
    pred_te < lower_bound,
    lower_bound + (pred_te - pred_te.min()) * 0.2,
    pred_te
)

# ìƒí•œì„ : 99.5 percentile ê¸°ì¤€ (ì—¬ìœ ìˆê²Œ)
upper_bound = train_p99 * 1.05
pred_te_adjusted = np.where(
    pred_te_adjusted > upper_bound,
    upper_bound + (pred_te_adjusted - upper_bound) * 0.5,
    pred_te_adjusted
)

# ìµœì¢… ë¬¼ë¦¬ì  ì œì•½
pred_te_final = np.clip(pred_te_adjusted, a_min=0, a_max=train_p99 * 1.1)

# -----------------------------
# 12) ì œì¶œ íŒŒì¼ ìƒì„±
# -----------------------------
submission = pd.DataFrame({"id": test["id"], "target": pred_te_final})
submission.to_csv("submission_optimized_v5.csv", index=False) 
print("\nğŸ’¾ submission_optimized_v5.csv ì €ì¥ ì™„ë£Œ!")
print(f"ì˜ˆì¸¡ ë²”ìœ„: {pred_te_final.min():.2f} ~ {pred_te_final.max():.2f}")
print(f"ì˜ˆì¸¡ í‰ê· : {pred_te_final.mean():.2f} (Train: {train_mean:.2f})")
print(f"ì˜ˆì¸¡ í‘œì¤€í¸ì°¨: {pred_te_final.std():.2f} (Train: {train_std:.2f})")

# -----------------------------
# 13) Meta ê³„ìˆ˜ ë¶„ì„
# -----------------------------
print("\nğŸ“Š Meta-Learner ê³„ìˆ˜:")
w = pd.Series(meta_learner.coef_, index=list(base_models.keys()))
w_norm = (w / w.abs().sum()).sort_values(ascending=False)
print(w_norm.round(3))

# -----------------------------
# 14) ğŸ”¥ ê°„ë‹¨í•œ Feature Importance (LightGBM ê¸°ì¤€)
# -----------------------------
print("\nğŸ” Feature Importance (Top 30)...")
lgb_model = LGBMRegressor(**LGB_PARAMS)
lgb_model.fit(X_all, y_all_log)
feat_imp = pd.DataFrame({
    'feature': feat_s2,
    'importance': lgb_model.feature_importances_
}).sort_values('importance', ascending=False)

print(feat_imp.head(30).to_string(index=False))
feat_imp.to_csv("feature_importance_v5.csv", index=False)
print("â¡ feature_importance_v5.csv ì €ì¥")

# -----------------------------
# 15) ğŸ¯ ì˜ˆì¸¡ ë¶„í¬ ë¹„êµ
# -----------------------------
print("\nğŸ“Š ì˜ˆì¸¡ ë¶„í¬ ë¹„êµ:")
print(f"Train ë¶„ìœ„ìˆ˜ (10%, 25%, 50%, 75%, 90%):")
train_quantiles = np.percentile(y_all, [10, 25, 50, 75, 90])
print(f"  {train_quantiles}")

print(f"Test ì˜ˆì¸¡ ë¶„ìœ„ìˆ˜ (10%, 25%, 50%, 75%, 90%):")
test_quantiles = np.percentile(pred_te_final, [10, 25, 50, 75, 90])
print(f"  {test_quantiles}")

# -----------------------------
# 16) ğŸ”¥ ì¶”ê°€ ì•™ìƒë¸”: ë‹¨ìˆœ í‰ê· ê³¼ í˜¼í•©
# -----------------------------
print("\nğŸ”„ ì¶”ê°€ ì•™ìƒë¸” ìƒì„± ì¤‘...")

# ë² ì´ìŠ¤ ëª¨ë¸ë“¤ì˜ ë‹¨ìˆœ í‰ê· 
test_preds_avg = np.mean(test_preds_s2, axis=1)
pred_te_simple = np.expm1(test_preds_avg)

# ğŸ”¥ Meta ì˜ˆì¸¡ê³¼ ë‹¨ìˆœ í‰ê·  í˜¼í•© (60:40)
pred_te_blended = 0.6 * pred_te_final + 0.4 * pred_te_simple
pred_te_blended = np.clip(pred_te_blended, a_min=0, a_max=train_p99 * 1.1)

submission_blended = pd.DataFrame({"id": test["id"], "target": pred_te_blended})
submission_blended.to_csv("submission_blended_v5.csv", index=False)
print("ğŸ’¾ submission_blended_v5.csv ì €ì¥ ì™„ë£Œ! (Meta 60% + Simple 40%)")
print(f"Blended ì˜ˆì¸¡ ë²”ìœ„: {pred_te_blended.min():.2f} ~ {pred_te_blended.max():.2f}")
print(f"Blended ì˜ˆì¸¡ í‰ê· : {pred_te_blended.mean():.2f}")

# -----------------------------
# 17) ğŸ¯ ê³ ìœ„í—˜ êµ¬ê°„ ë¶„ì„
# -----------------------------
print("\nğŸ¯ ê³ ìœ„í—˜ êµ¬ê°„ ì„±ëŠ¥ ë¶„ì„...")
risk_samples = train.loc[oof_valid_idx].query(
    "tou_relative_price == 1.0 and PF_recalc < 94"
)

if len(risk_samples) > 100:
    risk_idx = risk_samples.index
    risk_mae = mean_absolute_error(
        y_all.loc[risk_idx], 
        oof_pred_final[oof_valid_idx.isin(risk_idx)]
    )
    print(f"ê³ ìœ„í—˜ êµ¬ê°„ MAE: {risk_mae:.2f} (ìƒ˜í”Œ ìˆ˜: {len(risk_samples)})")
    
    normal_idx = oof_valid_idx[~oof_valid_idx.isin(risk_idx)]
    normal_mae = mean_absolute_error(
        y_all.loc[normal_idx], 
        oof_pred_final[oof_valid_idx.isin(normal_idx)]
    )
    print(f"ì¼ë°˜ êµ¬ê°„ MAE: {normal_mae:.2f}")
    print(f"ìœ„í—˜ë„ ë¹„ìœ¨: {risk_mae / normal_mae:.2f}x")

print("\n" + "="*60)
print("âœ… ìµœì í™” ì™„ë£Œ!")
print("="*60)
print("\nğŸ“Œ ì œì¶œ íŒŒì¼:")
print("  1. submission_optimized_v5.csv (ë©”ì¸)")
print("  2. submission_blended_v5.csv (ì•™ìƒë¸” í˜¼í•©)")
print("\nğŸ’¡ ê¶Œì¥ ì œì¶œ ìˆœì„œ:")
print("  1ë‹¨ê³„: submission_optimized_v5.csv")
print("  2ë‹¨ê³„: submission_blended_v5.csv")
print("="*60)