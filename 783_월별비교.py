# ============================================================
# LS ì „ë ¥ìš”ê¸ˆ ì˜ˆì¸¡ (ê°œì„ ëœ Stacking ì ìš© ë²„ì „)
# ============================================================
import warnings
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from catboost import CatBoostRegressor
from lightgbm import LGBMRegressor
from xgboost import XGBRegressor
from sklearn.cluster import KMeans # KMeans ì¶”ê°€
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.model_selection import TimeSeriesSplit
from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model import RidgeCV # RidgeCV ì‚¬ìš© (ìë™ Alpha ì°¾ê¸°)

warnings.filterwarnings("ignore")
plt.rcParams["font.family"] = "Malgun Gothic"
plt.rcParams["axes.unicode_minus"] = False

# -----------------------------
# 0) Load
# -----------------------------
# íŒŒì¼ ê²½ë¡œëŠ” ë™ì¼í•˜ë‹¤ê³  ê°€ì •
train = pd.read_csv("./data/train.csv")
test = pd.read_csv("./data/test.csv")

# -----------------------------
# 1) ì‹œê°„ íŒŒìƒ (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
# -----------------------------
REF_DATE = pd.Timestamp("2024-10-24")
def adjust_hour(dt):
    if pd.isna(dt): return np.nan
    return (dt.hour - 1) % 24 if dt.minute == 0 else dt.hour
def band_of_hour(h):
    if (22 <= h <= 23) or (0 <= h <= 7): return "ê²½ë¶€í•˜"
    if 16 <= h <= 21: return "ìµœëŒ€ë¶€í•˜"
    return "ì¤‘ê°„ë¶€í•˜"
def enrich(df):
    df["ì¸¡ì •ì¼ì‹œ"] = pd.to_datetime(df["ì¸¡ì •ì¼ì‹œ"], errors="coerce")
    df["ì›”"] = df["ì¸¡ì •ì¼ì‹œ"].dt.month
    df["ì¼"] = df["ì¸¡ì •ì¼ì‹œ"].dt.day
    df["ìš”ì¼"] = df["ì¸¡ì •ì¼ì‹œ"].dt.dayofweek
    df["ë‚ ì§œ"] = df['ì¸¡ì •ì¼ì‹œ'].dt.date # <-- 'ë‚ ì§œ' ì»¬ëŸ¼ ì¶”ê°€ (KMeansìš©)
    df["ì‹œê°„"] = df["ì¸¡ì •ì¼ì‹œ"].apply(adjust_hour)
    df["ì£¼ë§ì—¬ë¶€"] = (df["ìš”ì¼"] >= 5).astype(int)
    df["ê²¨ìš¸ì—¬ë¶€"] = df["ì›”"].isin([11, 12, 1, 2]).astype(int)
    df["period_flag"] = (df["ì¸¡ì •ì¼ì‹œ"] >= REF_DATE).astype(int)
    df["sin_time"] = np.sin(2 * np.pi * df["ì‹œê°„"] / 24)
    df["cos_time"] = np.cos(2 * np.pi * df["ì‹œê°„"] / 24)
    df["ë¶€í•˜êµ¬ë¶„"] = df["ì‹œê°„"].apply(band_of_hour)
    return df

train = enrich(train).sort_values("ì¸¡ì •ì¼ì‹œ").reset_index(drop=True)
test = enrich(test).sort_values("ì¸¡ì •ì¼ì‹œ").reset_index(drop=True)

# -----------------------------
# 2) ì¸ì½”ë”© (Test ë°ì´í„° ì—ëŸ¬ ì²˜ë¦¬ ì¶”ê°€)
# -----------------------------
le_job = LabelEncoder()
train["ì‘ì—…ìœ í˜•_encoded"] = le_job.fit_transform(train["ì‘ì—…ìœ í˜•"].astype(str))
# Test ë°ì´í„° ë³€í™˜ ì‹œ unseen ë¼ë²¨ ì²˜ë¦¬ (ê°€ì¥ í”í•œ ê°’ìœ¼ë¡œ ëŒ€ì²´)
test["ì‘ì—…ìœ í˜•_encoded"] = test["ì‘ì—…ìœ í˜•"].astype(str).map(lambda s: '-1' if s not in le_job.classes_ else s)
test["ì‘ì—…ìœ í˜•_encoded"] = le_job.transform(test["ì‘ì—…ìœ í˜•_encoded"].replace('-1', train["ì‘ì—…ìœ í˜•"].mode()[0])) # mode()ë¡œ ëŒ€ì²´

le_band = LabelEncoder()
train["ë¶€í•˜êµ¬ë¶„_encoded"] = le_band.fit_transform(train["ë¶€í•˜êµ¬ë¶„"].astype(str))
# Test ë°ì´í„° ë³€í™˜ ì‹œ unseen ë¼ë²¨ ì²˜ë¦¬
test["ë¶€í•˜êµ¬ë¶„_encoded"] = test["ë¶€í•˜êµ¬ë¶„"].astype(str).map(lambda s: '-1' if s not in le_band.classes_ else s)
test["ë¶€í•˜êµ¬ë¶„_encoded"] = le_band.transform(test["ë¶€í•˜êµ¬ë¶„_encoded"].replace('-1', train["ë¶€í•˜êµ¬ë¶„"].mode()[0]))

train["ì‹œê°„_ì‘ì—…ìœ í˜•"] = train["ì‹œê°„"].astype(str) + "_" + train["ì‘ì—…ìœ í˜•_encoded"].astype(str)
test["ì‹œê°„_ì‘ì—…ìœ í˜•"] = test["ì‹œê°„"].astype(str) + "_" + test["ì‘ì—…ìœ í˜•_encoded"].astype(str)
le_tj = LabelEncoder()
train["ì‹œê°„_ì‘ì—…ìœ í˜•_encoded"] = le_tj.fit_transform(train["ì‹œê°„_ì‘ì—…ìœ í˜•"])
# Test ë°ì´í„° ë³€í™˜ ì‹œ unseen ë¼ë²¨ ì²˜ë¦¬
test["ì‹œê°„_ì‘ì—…ìœ í˜•_encoded"] = test["ì‹œê°„_ì‘ì—…ìœ í˜•"].map(lambda s: '-1' if s not in le_tj.classes_ else s)
test["ì‹œê°„_ì‘ì—…ìœ í˜•_encoded"] = le_tj.transform(test["ì‹œê°„_ì‘ì—…ìœ í˜•_encoded"].replace('-1', train["ì‹œê°„_ì‘ì—…ìœ í˜•"].mode()[0]))

# -----------------------------
# 3) Stage1: ì „ë ¥íŠ¹ì„± ì˜ˆì¸¡ (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
# -----------------------------
targets_s1 = ["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)", "ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)", "ì§„ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)", "ì§€ìƒì—­ë¥ (%)", "ì§„ìƒì—­ë¥ (%)"]
feat_s1 = ["ì›”","ì¼","ìš”ì¼","ì‹œê°„","ì£¼ë§ì—¬ë¶€","ê²¨ìš¸ì—¬ë¶€","period_flag",
           "sin_time","cos_time","ì‘ì—…ìœ í˜•_encoded","ë¶€í•˜êµ¬ë¶„_encoded","ì‹œê°„_ì‘ì—…ìœ í˜•_encoded"]
stage1_models = { # í•˜ì´í¼íŒŒë¼ë¯¸í„°ëŠ” ì›ë³¸ ìœ ì§€
    "ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)": LGBMRegressor(n_estimators=2500, learning_rate=0.012, num_leaves=128, random_state=42),
    "ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)": CatBoostRegressor(iterations=2000, learning_rate=0.03, depth=7, verbose=0, random_seed=42),
    "ì§„ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)": CatBoostRegressor(iterations=2000, learning_rate=0.03, depth=7, verbose=0, random_seed=42),
    "ì§€ìƒì—­ë¥ (%)": LGBMRegressor(n_estimators=2000, learning_rate=0.02, num_leaves=96, random_state=42),
    "ì§„ìƒì—­ë¥ (%)": LGBMRegressor(n_estimators=2000, learning_rate=0.02, num_leaves=96, random_state=42),
}
tscv = TimeSeriesSplit(n_splits=5)
stage1_oof = pd.DataFrame(index=train.index)
stage1_test_pred = pd.DataFrame(index=test.index)
train_targets_true = train[targets_s1].copy() # ì›ë³¸ íƒ€ê²Ÿê°’ ì €ì¥

for tgt in targets_s1:
    oof_pred = np.full(len(train), np.nan, dtype=float)
    model = stage1_models[tgt]
    for fold, (tr_idx, va_idx) in enumerate(tscv.split(train), start=1):
        fold_model = model.__class__(**model.get_params())
        fold_model.fit(train.iloc[tr_idx][feat_s1], train_targets_true.iloc[tr_idx][tgt]) # ì›ë³¸ íƒ€ê²Ÿìœ¼ë¡œ í•™ìŠµ
        oof_pred[va_idx] = fold_model.predict(train.iloc[va_idx][feat_s1])
    missing = np.isnan(oof_pred)
    if missing.any():
        full_model = model.__class__(**model.get_params())
        full_model.fit(train[feat_s1], train_targets_true[tgt]) # ì›ë³¸ íƒ€ê²Ÿìœ¼ë¡œ í•™ìŠµ
        oof_pred[missing] = full_model.predict(train.loc[missing, feat_s1])
    stage1_oof[tgt] = oof_pred
    final_model = model.__class__(**model.get_params())
    final_model.fit(train[feat_s1], train_targets_true[tgt]) # ì›ë³¸ íƒ€ê²Ÿìœ¼ë¡œ í•™ìŠµ
    stage1_test_pred[tgt] = final_model.predict(test[feat_s1])

# Stage1 ì˜ˆì¸¡ ê²°ê³¼ë¥¼ train, test ë°ì´í„°í”„ë ˆì„ì— ì—…ë°ì´íŠ¸
for tgt in targets_s1:
    train[tgt] = stage1_oof[tgt]
    test[tgt] = stage1_test_pred[tgt]

# -----------------------------
# 4) EDA ê¸°ë°˜ ì—­ë¥  í”¼ì²˜ ìƒì„± (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
# -----------------------------
def add_pf_features(df: pd.DataFrame) -> pd.DataFrame:
    df["ìœ íš¨ì—­ë¥ (%)"] = df[["ì§€ìƒì—­ë¥ (%)", "ì§„ìƒì—­ë¥ (%)"]].max(axis=1)
    df["ì—­ë¥ _íŒ¨ë„í‹°ìœ¨"] = (90 - df["ìœ íš¨ì—­ë¥ (%)"]).clip(lower=0) * 0.01
    df["ì—­ë¥ _ë³´ìƒìœ¨"] = (df["ìœ íš¨ì—­ë¥ (%)"] - 90).clip(lower=0) * 0.005
    df["ì—­ë¥ _ì¡°ì •ìš”ìœ¨"] = df["ì—­ë¥ _ë³´ìƒìœ¨"] - df["ì—­ë¥ _íŒ¨ë„í‹°ìœ¨"]
    df["ì§€ìƒì—­ë¥ _ë³´ì •"] = df["ì§€ìƒì—­ë¥ (%)"].clip(lower=60)
    df["ì£¼ê°„ì—¬ë¶€"] = df["ë¶€í•˜êµ¬ë¶„"].isin(["ì¤‘ê°„ë¶€í•˜", "ìµœëŒ€ë¶€í•˜"]).astype(int)
    df["ë²•ì í˜ë„í‹°"] = ((df["ì§€ìƒì—­ë¥ _ë³´ì •"] < 90) & (df["ì£¼ê°„ì—¬ë¶€"] == 1)).astype(int)
    df["ì‹¤ì§ˆìœ„í—˜"] = ((df["ì§€ìƒì—­ë¥ _ë³´ì •"] < 94) & (df["ì£¼ê°„ì—¬ë¶€"] == 1)).astype(int)
    df["ê·¹ì €ì—­ë¥ "] = ((df["ì§€ìƒì—­ë¥ _ë³´ì •"] < 85) & (df["ì£¼ê°„ì—¬ë¶€"] == 1)).astype(int)
    df["ì—­ë¥ ë¶€ì¡±í­_94"] = (94 - df["ì§€ìƒì—­ë¥ _ë³´ì •"]).clip(lower=0) * df["ì£¼ê°„ì—¬ë¶€"]
    # ì—­ë¥  êµ¬ê°„ ë”ë¯¸
    df["ì—­ë¥ _60_85"] = (
        (df["ì§€ìƒì—­ë¥ _ë³´ì •"] >= 60)
        & (df["ì§€ìƒì—­ë¥ _ë³´ì •"] < 85)
        & (df["ì£¼ê°„ì—¬ë¶€"] == 1)
    ).astype(int)
    df["ì—­ë¥ _85_90"] = (
        (df["ì§€ìƒì—­ë¥ _ë³´ì •"] >= 85)
        & (df["ì§€ìƒì—­ë¥ _ë³´ì •"] < 90)
        & (df["ì£¼ê°„ì—¬ë¶€"] == 1)
    ).astype(int)
    df["ì—­ë¥ _90_94"] = (
        (df["ì§€ìƒì—­ë¥ _ë³´ì •"] >= 90)
        & (df["ì§€ìƒì—­ë¥ _ë³´ì •"] < 94)
        & (df["ì£¼ê°„ì—¬ë¶€"] == 1)
    ).astype(int)
    df["ì—­ë¥ _94_ì´ìƒ"] = (
        (df["ì§€ìƒì—­ë¥ _ë³´ì •"] >= 94) & (df["ì£¼ê°„ì—¬ë¶€"] == 1)
    ).astype(int)
    # ê°•í™”ëœ ì—­ë¥  ê¸°ë°˜ í”¼ì²˜
    df["ë¶€í•˜ì—­ë¥ ê³±_ê°•í™”"] = (
        df["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"] * df["ì—­ë¥ ë¶€ì¡±í­_94"] * df["ì£¼ê°„ì—¬ë¶€"] * 10
    )
    df["ì£¼ê°„_ë¶€ì¡±ë¥ "] = df["ì£¼ê°„ì—¬ë¶€"] * (90 - df["ì§€ìƒì—­ë¥ _ë³´ì •"]).clip(lower=0)
    df["ì£¼ê°„_ì¶”ê°€ìš”ìœ¨"] = df["ì£¼ê°„_ë¶€ì¡±ë¥ "] * 0.01
    return df
train = add_pf_features(train)
test = add_pf_features(test)

# -----------------------------
# 5) Lag/Rolling ìƒì„± (Test ë¶€ë¶„ ì •ë¦¬)
# -----------------------------
# Train ë°ì´í„° Lag/Rolling (ê¸°ì¡´ê³¼ ë™ì¼)
train["kwh_lag1"] = train["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"].shift(1)
train["kwh_lag24"] = train["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"].shift(24)
train["kwh_lag336"] = train["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"].shift(336)
train["kwh_lag336_ratio"] = train["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"] / (train["kwh_lag336"] + 1e-6)
train["kwh_roll12_mean"] = train["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"].shift(1).rolling(12).mean()
train["kwh_roll12_std"] = (
    train["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"].shift(1).rolling(12).std().fillna(0)
)
train["kwh_roll24_mean"] = train["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"].shift(1).rolling(24).mean()
train["kwh_roll24_std"] = (
    train["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"].shift(1).rolling(24).std().fillna(0)
)

# ë¬´íš¨ì „ë ¥ Lag/Rolling
train["kvarh_lag1"] = train["ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)"].shift(1)
train["kvarh_lag24"] = train["ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)"].shift(24)
train["kvarh_lag96"] = train["ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)"].shift(96)
train["kvarh_roll24_mean"] = (
    train["ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)"].shift(1).rolling(24).mean()
)
train["kvarh_roll24_std"] = (
    train["ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)"].shift(1).rolling(24).std().fillna(0)
)
train["kvarh_roll96_mean"] = (
    train["ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)"].shift(1).rolling(96).mean()
)
train["kvarh_roll96_std"] = (
    train["ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)"].shift(1).rolling(96).std().fillna(0)
)
train["kvarh_ë³€í™”ìœ¨_24h"] = (
    (train["ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)"] - train["kvarh_lag1"])
    / (train["kvarh_lag1"] + 1e-6)
)
train["ë¬´íš¨ì „ë ¥_ê¸‰ë“±"] = (train["kvarh_ë³€í™”ìœ¨_24h"] > 0.5).astype(int)
train["ì „ë ¥í’ˆì§ˆì§€ìˆ˜"] = (
    train["kvarh_roll24_mean"] / (train["kwh_roll24_mean"] + 1e-6)
)

# Test ë°ì´í„° Lag/Rolling (í™•ì¥)
hist_kwh = list(train["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"].tail(672).values.astype(float))
hist_kvarh = list(train["ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)"].tail(672).values.astype(float))

kwh_lag1_list, kwh_lag24_list, kwh_lag336_list = [], [], []
kwh_roll12_mean_list, kwh_roll12_std_list = [], []
kwh_roll24_mean_list, kwh_roll24_std_list = [], []
kwh_lag336_ratio_list = []

kvarh_lag1_list, kvarh_lag24_list, kvarh_lag96_list = [], [], []
kvarh_roll24_mean_list, kvarh_roll24_std_list = [], []
kvarh_roll96_mean_list, kvarh_roll96_std_list = [], []
kvarh_change24_list, kvarh_spike_list = [], []

for i in range(len(test)):
    kwh_lag1 = hist_kwh[-1] if len(hist_kwh) >= 1 else np.nan
    kwh_lag24 = hist_kwh[-24] if len(hist_kwh) >= 24 else np.nan
    kwh_lag336 = hist_kwh[-336] if len(hist_kwh) >= 336 else np.nan

    kwh_lag1_list.append(kwh_lag1)
    kwh_lag24_list.append(kwh_lag24)
    kwh_lag336_list.append(kwh_lag336)

    arr12 = np.array(hist_kwh[-12:])
    arr24 = np.array(hist_kwh[-24:])
    mean12 = arr12.mean() if arr12.size > 0 else np.nan
    std12 = arr12.std() if arr12.size > 1 else 0
    mean24 = arr24.mean() if arr24.size > 0 else np.nan
    std24 = arr24.std() if arr24.size > 1 else 0

    kwh_roll12_mean_list.append(mean12)
    kwh_roll12_std_list.append(std12)
    kwh_roll24_mean_list.append(mean24)
    kwh_roll24_std_list.append(std24)

    y_kwh = test.loc[i, "ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"]
    kwh_lag336_ratio_list.append(
        y_kwh / (kwh_lag336 + 1e-6) if not np.isnan(kwh_lag336) else np.nan
    )

    kvarh_lag1 = hist_kvarh[-1] if len(hist_kvarh) >= 1 else np.nan
    kvarh_lag24 = hist_kvarh[-24] if len(hist_kvarh) >= 24 else np.nan
    kvarh_lag96 = hist_kvarh[-96] if len(hist_kvarh) >= 96 else np.nan

    kvarh_lag1_list.append(kvarh_lag1)
    kvarh_lag24_list.append(kvarh_lag24)
    kvarh_lag96_list.append(kvarh_lag96)

    arr24_k = np.array(hist_kvarh[-24:])
    arr96_k = np.array(hist_kvarh[-96:])
    mean24_k = arr24_k.mean() if arr24_k.size > 0 else np.nan
    std24_k = arr24_k.std() if arr24_k.size > 1 else 0
    mean96_k = arr96_k.mean() if arr96_k.size > 0 else np.nan
    std96_k = arr96_k.std() if arr96_k.size > 1 else 0

    kvarh_roll24_mean_list.append(mean24_k)
    kvarh_roll24_std_list.append(std24_k)
    kvarh_roll96_mean_list.append(mean96_k)
    kvarh_roll96_std_list.append(std96_k)

    y_kvarh = test.loc[i, "ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)"]
    change24 = (
        (y_kvarh - kvarh_lag1) / (kvarh_lag1 + 1e-6)
        if not np.isnan(kvarh_lag1)
        else np.nan
    )
    kvarh_change24_list.append(change24)
    kvarh_spike_list.append(int(change24 > 0.5) if not np.isnan(change24) else 0)

    hist_kwh.append(y_kwh)
    hist_kvarh.append(y_kvarh)

test["kwh_lag1"] = kwh_lag1_list
test["kwh_lag24"] = kwh_lag24_list
test["kwh_lag336"] = kwh_lag336_list
test["kwh_lag336_ratio"] = kwh_lag336_ratio_list
test["kwh_roll12_mean"] = kwh_roll12_mean_list
test["kwh_roll12_std"] = kwh_roll12_std_list
test["kwh_roll24_mean"] = kwh_roll24_mean_list
test["kwh_roll24_std"] = kwh_roll24_std_list

test["kvarh_lag1"] = kvarh_lag1_list
test["kvarh_lag24"] = kvarh_lag24_list
test["kvarh_lag96"] = kvarh_lag96_list
test["kvarh_roll24_mean"] = kvarh_roll24_mean_list
test["kvarh_roll24_std"] = kvarh_roll24_std_list
test["kvarh_roll96_mean"] = kvarh_roll96_mean_list
test["kvarh_roll96_std"] = kvarh_roll96_std_list
test["kvarh_ë³€í™”ìœ¨_24h"] = kvarh_change24_list
test["ë¬´íš¨ì „ë ¥_ê¸‰ë“±"] = kvarh_spike_list
test["ì „ë ¥í’ˆì§ˆì§€ìˆ˜"] = (
    test["kvarh_roll24_mean"] / (test["kwh_roll24_mean"] + 1e-6)
)

# -----------------------------
# 6) ê³ ê¸‰ í”¼ì²˜ ì¶”ê°€ (ì½”ë“œ ì¤‘ë³µ ì œê±°)
# -----------------------------
def add_advanced_features(df, train_means=None): # is_train ëŒ€ì‹  train_means ì „ë‹¬
    df["ë¬´íš¨ìœ íš¨ë¹„ìœ¨"] = df["ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)"] / (df["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"] + 1e-6)
    df["ë¶€í•˜ì—­ë¥ ê³±"] = df["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"] * df["ì—­ë¥ ë¶€ì¡±í­_94"]
    df["ì—­ë¥ ë‹¹ì „ë ¥"] = df["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"] / (df["ì§€ìƒì—­ë¥ _ë³´ì •"] + 1e-6)
    df["ê°€ì„ìœ„í—˜"] = ((df["ì›”"].isin([9, 10])) & (df["ì‹¤ì§ˆìœ„í—˜"] == 1)).astype(int)
    df["ë™ì ˆê¸°ì•ˆì •"] = ((df["ê²¨ìš¸ì—¬ë¶€"] == 1) & (df["ì§€ìƒì—­ë¥ _ë³´ì •"] >= 94)).astype(int)

    if train_means: # Test ë°ì´í„° ì²˜ë¦¬
        df["ì—­ë¥ _ì›”í‰ê· "] = df["ì›”"].map(train_means["ì—­ë¥ _ì›”í‰ê· "])
        df["ì—­ë¥ _ì›”í‰ê· "].fillna(train_means["ì—­ë¥ _ì›”í‰ê· "].mean(), inplace=True) # í˜¹ì‹œ ëª¨ë¥¼ NaN ì²˜ë¦¬
    else: # Train ë°ì´í„° ì²˜ë¦¬
        df["ì—­ë¥ _ì›”í‰ê· "] = df.groupby("ì›”")["ì§€ìƒì—­ë¥ _ë³´ì •"].transform("mean")

    df["ì—­ë¥ _ì›”í‰ê· ì°¨ì´"] = df["ì§€ìƒì—­ë¥ _ë³´ì •"] - df["ì—­ë¥ _ì›”í‰ê· "]
    df["kwh_roll24_cv"] = df["kwh_roll24_std"] / (df["kwh_roll24_mean"] + 1e-6)
    df["kwh_roll12_cv"] = df["kwh_roll12_std"] / (df["kwh_roll12_mean"] + 1e-6)
    df["kvarh_roll24_cv"] = df["kvarh_roll24_std"] / (df["kvarh_roll24_mean"] + 1e-6)
    df["kvarh_roll96_cv"] = df["kvarh_roll96_std"] / (df["kvarh_roll96_mean"] + 1e-6)
    # ë³€í™”ìœ¨/ê¸‰ë“± í”¼ì²˜ (if/else ë°–ìœ¼ë¡œ ì´ë™)
    df["kwh_ë³€í™”ìœ¨_24h"] = ((df["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"] - df["kwh_lag24"]) / (df["kwh_lag24"] + 1e-6))
    df["ì „ë ¥ê¸‰ë“±"] = (df["kwh_ë³€í™”ìœ¨_24h"] > 0.5).astype(int)
    # ì—­ë¥  Ã— ë³€ë™ì„±/ë¬´íš¨ì „ë ¥ êµí˜¸ì‘ìš©
    df["ì—­ë¥ ë¶€ì¡±_ë³€ë™ê³±"] = df["ì—­ë¥ ë¶€ì¡±í­_94"] * df["kwh_roll24_cv"] * 100
    df["ì—­ë¥ ë¶€ì¡±_ë¬´íš¨ì „ë ¥"] = df["ì—­ë¥ ë¶€ì¡±í­_94"] * df["ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)"]
    df["ì£¼ê°„ìœ„í—˜_ê¸‰ë³€"] = df["ì‹¤ì§ˆìœ„í—˜"] * df["kwh_roll12_cv"] * 100
    df["ë¬´íš¨ì „ë ¥ë¹„ìœ¨_24h"] = df["kvarh_roll24_mean"] / (df["kwh_roll24_mean"] + 1e-6)
    df["ë¬´íš¨ì „ë ¥ë¹„ìœ¨_ë³€í™”"] = (
        (df["ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)"] - df["kvarh_lag1"]) / (df["kvarh_lag1"] + 1e-6)
    )
    df["ì „ë ¥í’ˆì§ˆì§€ìˆ˜"] = df["ë¬´íš¨ì „ë ¥ë¹„ìœ¨_24h"]
    if "ì—­ë¥ _90_94" in df.columns:
        df["ì—­ë¥ _90_94_ê°•í™”"] = df["ì—­ë¥ _90_94"] * df["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"] * 0.1
    return df

# Train í‰ê·  ê³„ì‚°
train_means_for_test = {"ì—­ë¥ _ì›”í‰ê· ": train.groupby("ì›”")["ì§€ìƒì—­ë¥ _ë³´ì •"].mean()}
train = add_advanced_features(train)
test = add_advanced_features(test, train_means=train_means_for_test)

# -----------------------------
# 6.5) ì¼ì¼ ì‘ì—… ìœ í˜• íŒ¨í„´ í”¼ì²˜ ìƒì„± (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
# -----------------------------
print("\nğŸ”„ ì¼ì¼ ì‘ì—… ìœ í˜• íŒ¨í„´ í”¼ì²˜ ìƒì„± ì¤‘...")
# ë‚ ì§œë³„, ì‹œê°„ëŒ€ë³„ ì‘ì—… ìœ í˜•_encodedë¥¼ í”¼ë²— í…Œì´ë¸”ë¡œ ë³€í™˜
# ì£¼ì˜: enrich í•¨ìˆ˜ì— 'ë‚ ì§œ' ì»¬ëŸ¼ ìƒì„±ì´ ì¶”ê°€ë˜ì—ˆëŠ”ì§€ í™•ì¸ í•„ìš” (ì´ë¯¸ ìœ„ì—ì„œ ì¶”ê°€í•¨)
train_pattern_pivot = train.pivot_table(index='ë‚ ì§œ', columns='ì‹œê°„', values='ì‘ì—…ìœ í˜•_encoded')
train_pattern_pivot = train_pattern_pivot.fillna(-1) # ê²°ì¸¡ì¹˜ë¥¼ -1ë¡œ ì±„ì›€
kmeans = KMeans(n_clusters=3, random_state=42, n_init='auto')
train_pattern_pivot['ì¼ì¼íŒ¨í„´ìœ í˜•'] = kmeans.fit_predict(train_pattern_pivot)
pattern_map = train_pattern_pivot[['ì¼ì¼íŒ¨í„´ìœ í˜•']].reset_index()
train = pd.merge(train, pattern_map, on='ë‚ ì§œ', how='left')

# Test ë°ì´í„° ì ìš©
test_pattern_pivot = test.pivot_table(index='ë‚ ì§œ', columns='ì‹œê°„', values='ì‘ì—…ìœ í˜•_encoded')
test_pattern_pivot = test_pattern_pivot.fillna(-1)
# Train ì»¬ëŸ¼ ê¸°ì¤€ìœ¼ë¡œ ë§ì¶”ê¸° (ìˆœì„œ ì¤‘ìš”)
train_cols_no_target = train_pattern_pivot.drop(columns='ì¼ì¼íŒ¨í„´ìœ í˜•').columns
test_pattern_pivot = test_pattern_pivot.reindex(columns=train_cols_no_target, fill_value=-1)
test_pattern_pivot['ì¼ì¼íŒ¨í„´ìœ í˜•'] = kmeans.predict(test_pattern_pivot[train_cols_no_target]) # ìˆœì„œ ë§ì¶˜ ë°ì´í„°ë¡œ ì˜ˆì¸¡
test_pattern_map = test_pattern_pivot[['ì¼ì¼íŒ¨í„´ìœ í˜•']].reset_index()
test = pd.merge(test, test_pattern_map, on='ë‚ ì§œ', how='left')

# NaN ì²˜ë¦¬ (ê°€ì¥ í”í•œ ê°’ìœ¼ë¡œ)
most_frequent_pattern = train['ì¼ì¼íŒ¨í„´ìœ í˜•'].mode()[0]
train['ì¼ì¼íŒ¨í„´ìœ í˜•'].fillna(most_frequent_pattern, inplace=True)
test['ì¼ì¼íŒ¨í„´ìœ í˜•'].fillna(most_frequent_pattern, inplace=True)
train['ì¼ì¼íŒ¨í„´ìœ í˜•'] = train['ì¼ì¼íŒ¨í„´ìœ í˜•'].astype(int)
test['ì¼ì¼íŒ¨í„´ìœ í˜•'] = test['ì¼ì¼íŒ¨í„´ìœ í˜•'].astype(int)
print(f"âœ… ì¼ì¼ íŒ¨í„´ ìœ í˜• ìƒì„± ì™„ë£Œ. ê°€ì¥ í”í•œ ìœ í˜•: {most_frequent_pattern}")

# -----------------------------
# 7) Stage2 Feature Set (íŒ¨í„´ í”¼ì²˜ ì¶”ê°€ í™•ì¸)
# -----------------------------
feat_s2 = [ # ê¸°ì¡´ í”¼ì²˜ ë¦¬ìŠ¤íŠ¸ ì‚¬ìš© + íŒ¨í„´ / ê°•í™” í”¼ì²˜ ì¶”ê°€
    "ì›”","ì¼","ìš”ì¼","ì‹œê°„","ì£¼ë§ì—¬ë¶€","ê²¨ìš¸ì—¬ë¶€","period_flag","sin_time","cos_time",
    "ì‘ì—…ìœ í˜•_encoded","ë¶€í•˜êµ¬ë¶„_encoded","ì‹œê°„_ì‘ì—…ìœ í˜•_encoded",
    "ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)","ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)","ì§„ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)",
    "ì§€ìƒì—­ë¥ (%)","ì§„ìƒì—­ë¥ (%)","ìœ íš¨ì—­ë¥ (%)","ì—­ë¥ _ì¡°ì •ìš”ìœ¨","ì§€ìƒì—­ë¥ _ë³´ì •",
    "ì£¼ê°„ì—¬ë¶€","ë²•ì í˜ë„í‹°","ì‹¤ì§ˆìœ„í—˜","ê·¹ì €ì—­ë¥ ","ì—­ë¥ ë¶€ì¡±í­_94",
    "ì—­ë¥ _60_85","ì—­ë¥ _85_90","ì—­ë¥ _90_94","ì—­ë¥ _94_ì´ìƒ","ì—­ë¥ _90_94_ê°•í™”",
    "ë¶€í•˜ì—­ë¥ ê³±","ë¶€í•˜ì—­ë¥ ê³±_ê°•í™”","ì£¼ê°„_ë¶€ì¡±ë¥ ","ì£¼ê°„_ì¶”ê°€ìš”ìœ¨",
    "ë¬´íš¨ìœ íš¨ë¹„ìœ¨","ì—­ë¥ ë‹¹ì „ë ¥","ê°€ì„ìœ„í—˜","ë™ì ˆê¸°ì•ˆì •",
    "ì—­ë¥ _ì›”í‰ê· ","ì—­ë¥ _ì›”í‰ê· ì°¨ì´",
    "ì—­ë¥ ë¶€ì¡±_ë³€ë™ê³±","ì—­ë¥ ë¶€ì¡±_ë¬´íš¨ì „ë ¥","ì£¼ê°„ìœ„í—˜_ê¸‰ë³€",
    "ë¬´íš¨ì „ë ¥ë¹„ìœ¨_24h","ë¬´íš¨ì „ë ¥ë¹„ìœ¨_ë³€í™”","ì „ë ¥í’ˆì§ˆì§€ìˆ˜",
    "kwh_lag1","kwh_lag24","kwh_lag336","kwh_lag336_ratio",
    "kwh_roll12_mean","kwh_roll12_std","kwh_roll12_cv",
    "kwh_roll24_mean","kwh_roll24_std","kwh_roll24_cv",
    "kwh_ë³€í™”ìœ¨_24h","ì „ë ¥ê¸‰ë“±",
    "kvarh_lag1","kvarh_lag24","kvarh_lag96",
    "kvarh_roll24_mean","kvarh_roll24_std","kvarh_roll24_cv",
    "kvarh_roll96_mean","kvarh_roll96_std","kvarh_roll96_cv",
    "kvarh_ë³€í™”ìœ¨_24h","ë¬´íš¨ì „ë ¥_ê¸‰ë“±",
    "ì¼ì¼íŒ¨í„´ìœ í˜•"
]
print(f"\nğŸ’¡ Stage 2 í”¼ì²˜ ê°œìˆ˜: {len(feat_s2)}")

# -----------------------------
# 8) Stage2 í•™ìŠµ (TimeSeriesSplit ê¸°ë°˜ Stackingìœ¼ë¡œ ë³€ê²½)
# -----------------------------
X_all = train[feat_s2].copy()
y_all = train["ì „ê¸°ìš”ê¸ˆ(ì›)"].copy()
y_all_log = np.log1p(y_all)
X_te = test[feat_s2].copy()

# Base ëª¨ë¸ ì •ì˜ (í•˜ì´í¼íŒŒë¼ë¯¸í„°ëŠ” ì›ë³¸ ìœ ì§€)
LGB_PARAMS = dict(n_estimators=2300, learning_rate=0.02, num_leaves=96, subsample=0.9, colsample_bytree=0.9, reg_alpha=3, reg_lambda=4, random_state=42)
XGB_PARAMS = dict(n_estimators=2300, learning_rate=0.02, max_depth=8, subsample=0.9, colsample_bytree=0.9, reg_lambda=4, reg_alpha=1, random_state=42)
CAT_PARAMS = dict(iterations=2000, learning_rate=0.02, depth=7, l2_leaf_reg=4, random_seed=42, verbose=0)
base_models = {
    "lgb": LGBMRegressor(**LGB_PARAMS),
    "xgb": XGBRegressor(**XGB_PARAMS),
    "cat": CatBoostRegressor(**CAT_PARAMS)
}

# Meta ëª¨ë¸ ì •ì˜
meta_learner = RidgeCV(alphas=np.logspace(-2, 2, 10), cv=None) # CVëŠ” ì§ì ‘ í•˜ë¯€ë¡œ None, Alpha ë²”ìœ„ ì§€ì •

# TimeSeriesSplit ì„¤ì • (Stage 1ê³¼ ë™ì¼í•˜ê²Œ 5-Fold)
tscv_s2 = TimeSeriesSplit(n_splits=5)

# OOF ì˜ˆì¸¡ê°’ ë° Test ì˜ˆì¸¡ê°’ ì €ì¥ ë°°ì—´ ì´ˆê¸°í™”
oof_preds_s2 = pd.DataFrame(index=X_all.index, columns=base_models.keys(), dtype=float)
test_preds_s2 = np.zeros((len(X_te), len(base_models)))

print("\nğŸš€ Stage 2 ëª¨ë¸ í•™ìŠµ ë° OOF ì˜ˆì¸¡ ìƒì„± ì‹œì‘...")
for fold, (tr_idx, va_idx) in enumerate(tscv_s2.split(X_all), start=1):
    print(f"--- Fold {fold} ---")
    X_tr, X_va = X_all.iloc[tr_idx], X_all.iloc[va_idx]
    y_tr_log, y_va_log = y_all_log.iloc[tr_idx], y_all_log.iloc[va_idx]

    fold_test_preds = [] # í˜„ì¬ Foldì—ì„œì˜ Test ì˜ˆì¸¡ê°’ ì €ì¥ìš©

    for name, model in base_models.items():
        print(f"  Training {name}...")
        fold_model = model.__class__(**model.get_params())
        fold_model.fit(X_tr, y_tr_log)

        # OOF ì˜ˆì¸¡ê°’ ì €ì¥
        oof_pred = fold_model.predict(X_va)
        oof_preds_s2.iloc[va_idx, list(base_models.keys()).index(name)] = oof_pred

        # Test ì˜ˆì¸¡ê°’ ëˆ„ì  (ê° Fold ëª¨ë¸ì˜ ì˜ˆì¸¡ì„ í‰ê· ë‚´ê¸° ìœ„í•¨)
        fold_test_preds.append(fold_model.predict(X_te))

    # í˜„ì¬ Foldì˜ Test ì˜ˆì¸¡ê°’ë“¤ì„ í‰ê· í•˜ì—¬ ëˆ„ì  ë°°ì—´ì— ë”í•¨
    test_preds_s2 += np.mean(fold_test_preds, axis=0)[:, np.newaxis] / tscv_s2.n_splits

print("\nâœ… OOF ì˜ˆì¸¡ ìƒì„± ì™„ë£Œ.")

# Meta-Learner í•™ìŠµ (OOF ì˜ˆì¸¡ê°’ì´ ìˆëŠ” ë¶€ë¶„ë§Œ ì‚¬ìš©)
oof_valid_idx = oof_preds_s2.dropna().index
print(f"\nğŸ§  Meta-Learner ({meta_learner.__class__.__name__}) í•™ìŠµ ì‹œì‘ (ë°ì´í„° {len(oof_valid_idx)}ê°œ)...")
meta_learner.fit(oof_preds_s2.loc[oof_valid_idx], y_all_log.loc[oof_valid_idx])
print(f"âœ… Meta-Learner í•™ìŠµ ì™„ë£Œ. ìµœì  Alpha: {meta_learner.alpha_:.4f}")
# ìµœì¢… ê°€ì¤‘ì¹˜ í™•ì¸ (RidgeCVëŠ” coef_ê°€ ì§ì ‘ ê°€ì¤‘ì¹˜ ì—­í• )
final_weights = meta_learner.coef_ / meta_learner.coef_.sum()
print("âš™ï¸ ìµœì¢… ê°€ì¤‘ì¹˜:", {name: f"{w:.3f}" for name, w in zip(base_models.keys(), final_weights)})

# ìµœì¢… Test ì˜ˆì¸¡ (í‰ê· ë‚¸ Base ëª¨ë¸ ì˜ˆì¸¡ê°’ì— Meta Learner ì ìš©)
print("\nğŸ§ª ìµœì¢… Test ì˜ˆì¸¡ ìƒì„±...")
meta_test_input = pd.DataFrame(test_preds_s2, columns=base_models.keys(), index=X_te.index)
pred_te_log = meta_learner.predict(meta_test_input)
pred_te = np.expm1(pred_te_log)

# OOF ê²€ì¦ ì ìˆ˜ ê³„ì‚° (Optional, ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ìš©)
oof_pred_final_log = meta_learner.predict(oof_preds_s2.loc[oof_valid_idx])
oof_pred_final = np.expm1(oof_pred_final_log)
oof_mae = mean_absolute_error(y_all.loc[oof_valid_idx], oof_pred_final)
oof_r2 = r2_score(y_all.loc[oof_valid_idx], oof_pred_final)
print(f"\nğŸ“Š OOF ê²€ì¦ (Stacking): MAE={oof_mae:.2f} | RÂ²={oof_r2:.4f}")


# -----------------------------
# 9) í›„ì²˜ë¦¬ ë° ì œì¶œ
# -----------------------------
low, high = np.percentile(pred_te, [0.2, 99.8]) # í´ë¦¬í•‘ ë²”ìœ„ëŠ” ìœ ì§€
pred_te = np.clip(pred_te, low, high)

submission = pd.DataFrame({"id": test["id"], "target": pred_te})
submission.to_csv("submission_ridge_stacking_cv.csv", index=False) # íŒŒì¼ëª… ë³€ê²½
print("\nğŸ’¾ submission_ridge_stacking_cv.csv ì €ì¥ ì™„ë£Œ!")
print(f"ì˜ˆì¸¡ ë²”ìœ„: {pred_te.min():.2f} ~ {pred_te.max():.2f}")
print(f"ì˜ˆì¸¡ í‰ê· : {pred_te.mean():.2f}")

# Feature Importance (ì „ì²´ ë°ì´í„°ë¡œ í•™ìŠµí•œ LGBM ëª¨ë¸ ê¸°ì¤€)
print("\nğŸš€ ì „ì²´ ë°ì´í„°ë¡œ LGBM ëª¨ë¸ ì¬í•™ìŠµ (Feature Importance ìš©)...")
lgb_full = LGBMRegressor(**LGB_PARAMS).fit(X_all, y_all_log)
feat_imp = pd.DataFrame({
    'feature': feat_s2,
    'importance': lgb_full.feature_importances_
}).sort_values('importance', ascending=False)
print("\nğŸ” Top 20 ì¤‘ìš” í”¼ì²˜:")
print(feat_imp.head(70).to_string(index=False))


feat_imp = pd.DataFrame({
    'feature': feat_s2,
    'importance': lgb_full.feature_importances_
}).sort_values('importance', ascending=False)
print("\nğŸ” Top 20 ì¤‘ìš” í”¼ì²˜:")
print(feat_imp.head(70).to_string(index=False))


print(f"ì˜ˆì¸¡ í‰ê· : {pred_te.mean():.2f}")
# Feature Importance (ì „ì²´ ë°ì´í„°ë¡œ í•™ìŠµí•œ LGBM ëª¨ë¸ ê¸°ì¤€)âŠ
print("\nğŸš€ ì „ì²´ ë°ì´í„°ë¡œ LGBM ëª¨ë¸ ì¬í•™ìŠµ (Feature Importance ìš©)...")
lgb_full = LGBMRegressor(**LGB_PARAMS).fit(X_all, y_all_log)
feat_imp = pd.DataFrame({
    'feature': feat_s2,
    'importance': lgb_full.feature_importances_
}).sort_values('importance', ascending=False)
print("\nğŸ” Top 20 ì¤‘ìš” í”¼ì²˜:")
print(feat_imp.head(20).to_string(index=False))
# -----------------------------
# 10) ì›”ë³„ ê²€ì¦ (1~11ì›”)
# -----------------------------
xgb_full = XGBRegressor(**XGB_PARAMS)
xgb_full.fit(X_all, y_all_log)
cat_full = CatBoostRegressor(**CAT_PARAMS)
cat_full.fit(X_all, y_all_log)
stack_inputs_full = pd.DataFrame({
    "lgb": lgb_full.predict(X_all),
    "xgb": xgb_full.predict(X_all),
    "cat": cat_full.predict(X_all),
}, index=X_all.index)
train_preds_full = np.expm1(meta_learner.predict(stack_inputs_full))
monthly_scores = []
for month in sorted(train["ì›”"].unique()):
    mask = train["ì›”"] == month
    mae_month = mean_absolute_error(y_all[mask], train_preds_full[mask])
    r2_month = r2_score(y_all[mask], train_preds_full[mask])
    monthly_scores.append((month, mae_month, r2_month))
    print(f"ğŸ“… {month}ì›” MAE={mae_month:.2f} | RÂ²={r2_month:.4f}")
if monthly_scores:
    best_month, best_mae, best_r2 = min(monthly_scores, key=lambda x: x[1])
    print(f"\nâœ… MAEê°€ ê°€ì¥ ë‚®ì€ ë‹¬: {best_month}ì›” (MAE={best_mae:.2f}, RÂ²={best_r2:.4f})")
