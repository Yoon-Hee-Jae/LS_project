#!/usr/bin/env python
# ============================================================
# EDA ê¸°ë°˜ ì—­ë¥  í”¼ì²˜ ê°•í™”íŒ + ê³ ê¸‰ í”¼ì²˜ (1,2,3)
#  - ì „ë ¥Ã—ì—­ë¥  êµí˜¸ì‘ìš©
#  - ê³„ì ˆÃ—ì—­ë¥  êµí˜¸ì‘ìš©
#  - ë¶€í•˜ ë³€ë™ì„±
# ============================================================
import warnings

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from catboost import CatBoostRegressor
from lightgbm import LGBMRegressor
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.model_selection import TimeSeriesSplit
from sklearn.preprocessing import LabelEncoder
from xgboost import XGBRegressor

warnings.filterwarnings("ignore")

# -----------------------------
# 0) Load
# -----------------------------
train = pd.read_csv("./data/train_.csv")
test = pd.read_csv("./data/test_.csv")

# -----------------------------
# 1) ì‹œê°„ íŒŒìƒ (ë² ì´ìŠ¤ì™€ ë™ì¼)
# -----------------------------
REF_DATE = pd.Timestamp("2024-10-24")


def adjust_hour(dt):
    if pd.isna(dt):
        return np.nan
    return (dt.hour - 1) % 24 if dt.minute == 0 else dt.hour


def band_of_hour(h):
    if (22 <= h <= 23) or (0 <= h <= 7):
        return "ê²½ë¶€í•˜"
    if 16 <= h <= 21:
        return "ìµœëŒ€ë¶€í•˜"
    return "ì¤‘ê°„ë¶€í•˜"


def enrich(df):
    df["ì¸¡ì •ì¼ì‹œ"] = pd.to_datetime(df["ì¸¡ì •ì¼ì‹œ"], errors="coerce")
    df["ì›”"] = df["ì¸¡ì •ì¼ì‹œ"].dt.month
    df["ì¼"] = df["ì¸¡ì •ì¼ì‹œ"].dt.day
    df["ìš”ì¼"] = df["ì¸¡ì •ì¼ì‹œ"].dt.dayofweek
    df["ì‹œê°„"] = df["ì¸¡ì •ì¼ì‹œ"].apply(adjust_hour)
    df["ì£¼ë§ì—¬ë¶€"] = (df["ìš”ì¼"] >= 5).astype(int)
    df["ê²¨ìš¸ì—¬ë¶€"] = df["ì›”"].isin([11, 12, 1, 2]).astype(int)
    df["period_flag"] = (df["ì¸¡ì •ì¼ì‹œ"] >= REF_DATE).astype(int)
    df["sin_time"] = np.sin(2 * np.pi * df["ì‹œê°„"] / 24)
    df["cos_time"] = np.cos(2 * np.pi * df["ì‹œê°„"] / 24)
    df["ë¶€í•˜êµ¬ë¶„"] = df["ì‹œê°„"].apply(band_of_hour)
    return df


train = enrich(train).sort_values("ì¸¡ì •ì¼ì‹œ").reset_index(drop=True)
test = enrich(test).sort_values("ì¸¡ì •ì¼ì‹œ").reset_index(drop=True)

# ì¸ì½”ë”©
le_job = LabelEncoder()
train["ì‘ì—…ìœ í˜•_encoded"] = le_job.fit_transform(train["ì‘ì—…ìœ í˜•"].astype(str))
test["ì‘ì—…ìœ í˜•_encoded"] = le_job.transform(test["ì‘ì—…ìœ í˜•"].astype(str))

le_band = LabelEncoder()
train["ë¶€í•˜êµ¬ë¶„_encoded"] = le_band.fit_transform(train["ë¶€í•˜êµ¬ë¶„"].astype(str))
test["ë¶€í•˜êµ¬ë¶„_encoded"] = le_band.transform(test["ë¶€í•˜êµ¬ë¶„"].astype(str))

train["ì‹œê°„_ì‘ì—…ìœ í˜•"] = (
    train["ì‹œê°„"].astype(str) + "_" + train["ì‘ì—…ìœ í˜•_encoded"].astype(str)
)
test["ì‹œê°„_ì‘ì—…ìœ í˜•"] = (
    test["ì‹œê°„"].astype(str) + "_" + test["ì‘ì—…ìœ í˜•_encoded"].astype(str)
)
le_tj = LabelEncoder()
train["ì‹œê°„_ì‘ì—…ìœ í˜•_encoded"] = le_tj.fit_transform(train["ì‹œê°„_ì‘ì—…ìœ í˜•"])
test["ì‹œê°„_ì‘ì—…ìœ í˜•_encoded"] = le_tj.transform(test["ì‹œê°„_ì‘ì—…ìœ í˜•"])

# -----------------------------
# 2) Stage1: ì „ë ¥íŠ¹ì„± ì˜ˆì¸¡
# -----------------------------
targets_s1 = [
    "ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)",
    "ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)",
    "ì§„ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)",
    "ì§€ìƒì—­ë¥ (%)",
    "ì§„ìƒì—­ë¥ (%)",
]
feat_s1 = [
    "ì›”",
    "ì¼",
    "ìš”ì¼",
    "ì‹œê°„",
    "ì£¼ë§ì—¬ë¶€",
    "ê²¨ìš¸ì—¬ë¶€",
    "period_flag",
    "sin_time",
    "cos_time",
    "ì‘ì—…ìœ í˜•_encoded",
    "ë¶€í•˜êµ¬ë¶„_encoded",
    "ì‹œê°„_ì‘ì—…ìœ í˜•_encoded",
]

stage1_models = {
    "ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)": LGBMRegressor(
        n_estimators=2500, learning_rate=0.012, num_leaves=128, random_state=42
    ),
    "ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)": CatBoostRegressor(
        iterations=2000, learning_rate=0.03, depth=7, verbose=0, random_seed=42
    ),
    "ì§„ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)": CatBoostRegressor(
        iterations=2000, learning_rate=0.03, depth=7, verbose=0, random_seed=42
    ),
    "ì§€ìƒì—­ë¥ (%)": LGBMRegressor(
        n_estimators=2000, learning_rate=0.02, num_leaves=96, random_state=42
    ),
    "ì§„ìƒì—­ë¥ (%)": LGBMRegressor(
        n_estimators=2000, learning_rate=0.02, num_leaves=96, random_state=42
    ),
}

tscv = TimeSeriesSplit(n_splits=5)
stage1_oof = pd.DataFrame(index=train.index)
stage1_test_pred = pd.DataFrame(index=test.index)
train_targets_true = train[targets_s1].copy()

for tgt in targets_s1:
    oof_pred = np.full(len(train), np.nan, dtype=float)
    model = stage1_models[tgt]

    for fold, (tr_idx, va_idx) in enumerate(tscv.split(train), start=1):
        fold_model = stage1_models[tgt].__class__(**stage1_models[tgt].get_params())
        fold_model.fit(train.iloc[tr_idx][feat_s1], train.iloc[tr_idx][tgt])
        oof_pred[va_idx] = fold_model.predict(train.iloc[va_idx][feat_s1])

    # TimeSeriesSplit keeps early segment (first fold) as validation; ensure no NaNs
    missing = np.isnan(oof_pred)
    if missing.any():
        full_model = stage1_models[tgt].__class__(**stage1_models[tgt].get_params())
        full_model.fit(train[feat_s1], train[tgt])
        oof_pred[missing] = full_model.predict(train.loc[missing, feat_s1])

    stage1_oof[tgt] = oof_pred

    # ìµœì¢… 12ì›” ì˜ˆì¸¡ìš© ëª¨ë¸ (1~11ì›” ì „ì²´ë¡œ í•™ìŠµ)
    final_model = stage1_models[tgt].__class__(**stage1_models[tgt].get_params())
    final_model.fit(train[feat_s1], train_targets_true[tgt])
    stage1_test_pred[tgt] = final_model.predict(test[feat_s1])

# Stage1 ì˜ˆì¸¡ì¹˜ë¡œ train/test ê°±ì‹ 
for tgt in targets_s1:
    train[f"{tgt}_true"] = train_targets_true[tgt]
    train[tgt] = stage1_oof[tgt]
    test[tgt] = stage1_test_pred[tgt]

# Stage1 ì˜ˆì¸¡ì¹˜ ë¶„í¬ í™•ì¸
print("\nğŸ“Š Stage1 ì§€ìƒì—­ë¥ (%) ì˜ˆì¸¡ ë¶„í¬:")
print(train["ì§€ìƒì—­ë¥ (%)"].describe())
print(f"95% ì´ˆê³¼ ê±´ìˆ˜: {(train['ì§€ìƒì—­ë¥ (%)'] > 95).sum()}ê±´")
print(f"94% ë¯¸ë§Œ ê±´ìˆ˜: {(train['ì§€ìƒì—­ë¥ (%)'] < 94).sum()}ê±´")

# -----------------------------
# 3) EDA ê¸°ë°˜ ì—­ë¥  í”¼ì²˜ ìƒì„±
# -----------------------------
def add_pf_features(df: pd.DataFrame) -> pd.DataFrame:
    """EDA ì¸ì‚¬ì´íŠ¸ ê¸°ë°˜ ì—­ë¥  í”¼ì²˜ ìƒì„±"""
    # ê¸°ë³¸ ì—­ë¥  í”¼ì²˜
    df["ìœ íš¨ì—­ë¥ (%)"] = df[["ì§€ìƒì—­ë¥ (%)", "ì§„ìƒì—­ë¥ (%)"]].max(axis=1)
    df["ì—­ë¥ _íŒ¨ë„í‹°ìœ¨"] = (90 - df["ìœ íš¨ì—­ë¥ (%)"]).clip(lower=0) * 0.01
    df["ì—­ë¥ _ë³´ìƒìœ¨"] = (df["ìœ íš¨ì—­ë¥ (%)"] - 90).clip(lower=0) * 0.005
    df["ì—­ë¥ _ì¡°ì •ìš”ìœ¨"] = df["ì—­ë¥ _ë³´ìƒìœ¨"] - df["ì—­ë¥ _íŒ¨ë„í‹°ìœ¨"]
    
    # EDA ê¸°ë°˜ ìƒˆ í”¼ì²˜
    df["ì§€ìƒì—­ë¥ _ë³´ì •"] = df["ì§€ìƒì—­ë¥ (%)"].clip(lower=60)  # upper ì œê±° (95% ì´ìƒ ì •ë³´ ë³´ì¡´)
    df["ì£¼ê°„ì—¬ë¶€"] = df["ë¶€í•˜êµ¬ë¶„"].isin(["ì¤‘ê°„ë¶€í•˜", "ìµœëŒ€ë¶€í•˜"]).astype(int)
    
    # ë²•ì  í˜ë„í‹° (90% ë¯¸ë§Œ)
    df["ë²•ì í˜ë„í‹°"] = ((df["ì§€ìƒì—­ë¥ _ë³´ì •"] < 90) & (df["ì£¼ê°„ì—¬ë¶€"] == 1)).astype(int)
    
    # ì‹¤ì§ˆ ìœ„í—˜ (94% ë¯¸ë§Œ) â† EDAì—ì„œ ë°œê²¬í•œ í•µì‹¬ ì„ê³„ì !
    df["ì‹¤ì§ˆìœ„í—˜"] = ((df["ì§€ìƒì—­ë¥ _ë³´ì •"] < 94) & (df["ì£¼ê°„ì—¬ë¶€"] == 1)).astype(int)
    
    # ê·¹ì € ì—­ë¥  (85% ë¯¸ë§Œ) â† ë²•ì í˜ë„í‹°ì™€ ì°¨ë³„í™”
    df["ê·¹ì €ì—­ë¥ "] = ((df["ì§€ìƒì—­ë¥ _ë³´ì •"] < 85) & (df["ì£¼ê°„ì—¬ë¶€"] == 1)).astype(int)
    
    # ì—­ë¥  ë¶€ì¡±í­ (94% ê¸°ì¤€, ì•¼ê°„ ë…¸ì´ì¦ˆ ì œê±°)
    df["ì—­ë¥ ë¶€ì¡±í­_94"] = (94 - df["ì§€ìƒì—­ë¥ _ë³´ì •"]).clip(lower=0) * df["ì£¼ê°„ì—¬ë¶€"]
    
    return df


train = add_pf_features(train)
test = add_pf_features(test)

# -----------------------------
# 4) Lag/Rolling ìƒì„± (ì „ë ¥ì‚¬ìš©ëŸ‰)
# -----------------------------
# lag / rolling for train (shifted to avoid leakage)
train["kwh_lag1"] = train["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"].shift(1)
train["kwh_lag24"] = train["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"].shift(24)
train["kwh_lag96"] = train["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"].shift(96)
train["kwh_lag672"] = train["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"].shift(672)

train["kwh_roll24_mean"] = train["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"].shift(1).rolling(24).mean()
train["kwh_roll24_std"] = (
    train["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"].shift(1).rolling(24).std().fillna(0)
)
train["kwh_roll96_mean"] = train["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"].shift(1).rolling(96).mean()
train["kwh_roll96_std"] = (
    train["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"].shift(1).rolling(96).std().fillna(0)
)
train["kwh_roll672_mean"] = train["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"].shift(1).rolling(672).mean()
train["kwh_roll672_std"] = (
    train["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"].shift(1).rolling(672).std().fillna(0)
)

# lag/rolling for test using recursive approach
hist = list(train["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"].tail(672).values.astype(float))
lag1_list, lag24_list, lag96_list, lag672_list = [], [], [], []
r24m, r24s, r96m, r96s, r672m, r672s = [], [], [], [], [], []

for y in test["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"].values.astype(float):
    lag1_list.append(hist[-1] if len(hist) >= 1 else np.nan)
    lag24_list.append(hist[-24] if len(hist) >= 24 else np.nan)
    lag96_list.append(hist[-96] if len(hist) >= 96 else np.nan)
    lag672_list.append(hist[-672] if len(hist) >= 672 else np.nan)

    arr24 = np.array(hist[-24:]) if len(hist) >= 24 else np.array(hist)
    arr96 = np.array(hist[-96:]) if len(hist) >= 96 else np.array(hist)
    arr672 = np.array(hist[-672:]) if len(hist) >= 672 else np.array(hist)

    r24m.append(arr24.mean() if arr24.size > 0 else np.nan)
    r24s.append(arr24.std() if arr24.size > 1 else 0)
    r96m.append(arr96.mean() if arr96.size > 0 else np.nan)
    r96s.append(arr96.std() if arr96.size > 1 else 0)
    r672m.append(arr672.mean() if arr672.size > 0 else np.nan)
    r672s.append(arr672.std() if arr672.size > 1 else 0)

    hist.append(y)

test["kwh_lag1"] = lag1_list
test["kwh_lag24"] = lag24_list
test["kwh_lag96"] = lag96_list
test["kwh_lag672"] = lag672_list
test["kwh_roll24_mean"] = r24m
test["kwh_roll24_std"] = r24s
test["kwh_roll96_mean"] = r96m
test["kwh_roll96_std"] = r96s
test["kwh_roll672_mean"] = r672m
test["kwh_roll672_std"] = r672s

# -----------------------------
# 5) ê³ ê¸‰ í”¼ì²˜ ì¶”ê°€ (1,2,3)
# -----------------------------
def add_advanced_features(df, is_train=True):
    """
    ê³ ê¸‰ í”¼ì²˜ ì¶”ê°€
    1. ì „ë ¥Ã—ì—­ë¥  êµí˜¸ì‘ìš©
    2. ê³„ì ˆÃ—ì—­ë¥  êµí˜¸ì‘ìš©
    3. ë¶€í•˜ ë³€ë™ì„±
    """
    # === 1. ì „ë ¥Ã—ì—­ë¥  êµí˜¸ì‘ìš© ===
    # ë¬´íš¨ì „ë ¥ / ìœ íš¨ì „ë ¥ ë¹„ìœ¨ (ì—­ë¥ ì´ ë‚˜ì ìˆ˜ë¡ ì»¤ì§)
    df["ë¬´íš¨ìœ íš¨ë¹„ìœ¨"] = df["ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)"] / (df["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"] + 1e-6)
    
    # ì „ë ¥ì‚¬ìš©ëŸ‰ Ã— ì—­ë¥ ë¶€ì¡±í­ (í° ë¶€í•˜ + ë‚˜ìœ ì—­ë¥  = í° íŒ¨ë„í‹°)
    df["ë¶€í•˜ì—­ë¥ ê³±"] = df["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"] * df["ì—­ë¥ ë¶€ì¡±í­_94"]
    
    # ì—­ë¥  ëŒ€ë¹„ ì „ë ¥ì‚¬ìš©ëŸ‰
    df["ì—­ë¥ ë‹¹ì „ë ¥"] = df["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"] / (df["ì§€ìƒì—­ë¥ _ë³´ì •"] + 1e-6)
    
    # === 2. ê³„ì ˆÃ—ì—­ë¥  êµí˜¸ì‘ìš© ===
    # 9-10ì›” ìœ„í—˜êµ¬ê°„ (EDAì—ì„œ ë°œê²¬í•œ ìµœì•…ì˜ ì¡°í•©)
    df["ê°€ì„ìœ„í—˜"] = (
        (df["ì›”"].isin([9, 10])) & 
        (df["ì‹¤ì§ˆìœ„í—˜"] == 1)
    ).astype(int)
    
    # 1-2ì›” ê³ ë¶€í•˜ + ì—­ë¥ ì–‘í˜¸ (ë‚œë°© ì‹œì¦Œ)
    df["ë™ì ˆê¸°ì•ˆì •"] = (
        (df["ê²¨ìš¸ì—¬ë¶€"] == 1) & 
        (df["ì§€ìƒì—­ë¥ _ë³´ì •"] >= 94)
    ).astype(int)
    
    # ì›”ë³„ í‰ê·  ì—­ë¥  ëŒ€ë¹„ í¸ì°¨
    df["ì—­ë¥ _ì›”í‰ê· "] = df.groupby("ì›”")["ì§€ìƒì—­ë¥ _ë³´ì •"].transform("mean")
    df["ì—­ë¥ _ì›”í‰ê· ì°¨ì´"] = df["ì§€ìƒì—­ë¥ _ë³´ì •"] - df["ì—­ë¥ _ì›”í‰ê· "]
    
    # === 3. ë¶€í•˜ ë³€ë™ì„± ===
    # ìµœê·¼ 24ì‹œê°„ ë³€ë™ê³„ìˆ˜ (CV = std/mean)
    df["kwh_roll24_cv"] = df["kwh_roll24_std"] / (df["kwh_roll24_mean"] + 1e-6)
    
    if is_train:
        # lag ëŒ€ë¹„ ë³€í™”ìœ¨
        df["kwh_ë³€í™”ìœ¨_24h"] = (
            (df["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"] - df["kwh_lag24"]) / (df["kwh_lag24"] + 1e-6)
        )
        
        # ê¸‰ë“± í”Œë˜ê·¸ (ì „ë‚  ëŒ€ë¹„ 50% ì´ìƒ ì¦ê°€)
        df["ì „ë ¥ê¸‰ë“±"] = (df["kwh_ë³€í™”ìœ¨_24h"] > 0.5).astype(int)
    else:
        # testëŠ” lag24ê°€ ìˆìœ¼ë¯€ë¡œ ë™ì¼í•˜ê²Œ ê³„ì‚° ê°€ëŠ¥
        df["kwh_ë³€í™”ìœ¨_24h"] = (
            (df["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"] - df["kwh_lag24"]) / (df["kwh_lag24"] + 1e-6)
        )
        df["ì „ë ¥ê¸‰ë“±"] = (df["kwh_ë³€í™”ìœ¨_24h"] > 0.5).astype(int)
    
    return df


train = add_advanced_features(train, is_train=True)
test = add_advanced_features(test, is_train=False)

# ìƒˆ í”¼ì²˜ ë¶„í¬ í™•ì¸
print("\nğŸ“Š ìƒˆ ì—­ë¥  í”¼ì²˜ ë¶„í¬ (train):")
print(f"ë²•ì í˜ë„í‹° ë°œìƒ: {train['ë²•ì í˜ë„í‹°'].sum()}ê±´ ({train['ë²•ì í˜ë„í‹°'].mean()*100:.1f}%)")
print(f"ì‹¤ì§ˆìœ„í—˜ ë°œìƒ: {train['ì‹¤ì§ˆìœ„í—˜'].sum()}ê±´ ({train['ì‹¤ì§ˆìœ„í—˜'].mean()*100:.1f}%)")
print(f"ê·¹ì €ì—­ë¥  ë°œìƒ: {train['ê·¹ì €ì—­ë¥ '].sum()}ê±´ ({train['ê·¹ì €ì—­ë¥ '].mean()*100:.1f}%)")
print(f"ê°€ì„ìœ„í—˜ ë°œìƒ: {train['ê°€ì„ìœ„í—˜'].sum()}ê±´ ({train['ê°€ì„ìœ„í—˜'].mean()*100:.1f}%)")
print(f"ì—­ë¥ ë¶€ì¡±í­_94 í‰ê· : {train['ì—­ë¥ ë¶€ì¡±í­_94'].mean():.3f}")
print(f"ë¶€í•˜ì—­ë¥ ê³± í‰ê· : {train['ë¶€í•˜ì—­ë¥ ê³±'].mean():.3f}")

# -----------------------------
# 6) Stage2: ìš”ê¸ˆ ì˜ˆì¸¡ (EDA + ê³ ê¸‰ í”¼ì²˜)
# -----------------------------
feat_s2 = [
    "ì›”",
    "ì¼",
    "ìš”ì¼",
    "ì‹œê°„",
    "ì£¼ë§ì—¬ë¶€",
    "ê²¨ìš¸ì—¬ë¶€",
    "period_flag",
    "sin_time",
    "cos_time",
    "ì‘ì—…ìœ í˜•_encoded",
    "ë¶€í•˜êµ¬ë¶„_encoded",
    "ì‹œê°„_ì‘ì—…ìœ í˜•_encoded",
    "ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)",
    "ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)",
    "ì§„ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)",
    "ì§€ìƒì—­ë¥ (%)",
    "ì§„ìƒì—­ë¥ (%)",
    "ìœ íš¨ì—­ë¥ (%)",
    "ì—­ë¥ _ì¡°ì •ìš”ìœ¨",
    # EDA ê¸°ë°˜ ì—­ë¥  í”¼ì²˜
    "ì§€ìƒì—­ë¥ _ë³´ì •",
    "ì£¼ê°„ì—¬ë¶€",
    "ë²•ì í˜ë„í‹°",
    "ì‹¤ì§ˆìœ„í—˜",
    "ê·¹ì €ì—­ë¥ ",
    "ì—­ë¥ ë¶€ì¡±í­_94",
    # ê³ ê¸‰ í”¼ì²˜ (1,2,3)
    "ë¬´íš¨ìœ íš¨ë¹„ìœ¨",
    "ë¶€í•˜ì—­ë¥ ê³±",
    "ì—­ë¥ ë‹¹ì „ë ¥",
    "ê°€ì„ìœ„í—˜",
    "ë™ì ˆê¸°ì•ˆì •",
    "ì—­ë¥ _ì›”í‰ê· ",
    "ì—­ë¥ _ì›”í‰ê· ì°¨ì´",
    "kwh_roll24_cv",
    "kwh_ë³€í™”ìœ¨_24h",
    "ì „ë ¥ê¸‰ë“±",
    # lag/rolling
    "kwh_lag1",
    "kwh_lag24",
    "kwh_lag96",
    "kwh_lag672",
    "kwh_roll24_mean",
    "kwh_roll24_std",
    "kwh_roll96_mean",
    "kwh_roll96_std",
    "kwh_roll672_mean",
    "kwh_roll672_std",
]

X_all = train[feat_s2].copy()
y_all = train["ì „ê¸°ìš”ê¸ˆ(ì›)"].copy()

idx_tr = train["ì›”"] < 11
idx_va = train["ì›”"] == 11

X_tr = X_all[idx_tr]
X_va = X_all[idx_va]
y_tr = y_all[idx_tr]
y_va = y_all[idx_va]

y_tr_log = np.log1p(y_tr)
y_all_log = np.log1p(y_all)

LGB_PARAMS = dict(
    n_estimators=2300,
    learning_rate=0.02,
    num_leaves=96,
    subsample=0.9,
    colsample_bytree=0.9,
    reg_alpha=3,
    reg_lambda=4,
    random_state=42,
)
XGB_PARAMS = dict(
    n_estimators=2300,
    learning_rate=0.02,
    max_depth=8,
    subsample=0.9,
    colsample_bytree=0.9,
    reg_lambda=4,
    reg_alpha=1,
    random_state=42,
)
CAT_PARAMS = dict(
    iterations=2000,
    learning_rate=0.02,
    depth=7,
    l2_leaf_reg=4,
    random_seed=42,
    verbose=0,
)

lgb = LGBMRegressor(**LGB_PARAMS)
xgb = XGBRegressor(**XGB_PARAMS)
cat = CatBoostRegressor(**CAT_PARAMS)

lgb.fit(X_tr, y_tr_log)
xgb.fit(X_tr, y_tr_log)
cat.fit(X_tr, y_tr_log)

pred_va = (
    0.5 * np.expm1(lgb.predict(X_va))
    + 0.3 * np.expm1(xgb.predict(X_va))
    + 0.2 * np.expm1(cat.predict(X_va))
)
mae = mean_absolute_error(y_va, pred_va)
r2 = r2_score(y_va, pred_va)
print(f"\nğŸ“Š 11ì›” ê²€ì¦: MAE={mae:.2f} | RÂ²={r2:.4f}")

# Feature Importance í™•ì¸ (LightGBM ê¸°ì¤€)
feat_imp = pd.DataFrame({
    'feature': feat_s2,
    'importance': lgb.feature_importances_
}).sort_values('importance', ascending=False)

print("\nğŸ” Top 20 ì¤‘ìš” í”¼ì²˜:")
print(feat_imp.head(20).to_string(index=False))

plt.figure(figsize=(8, 4.8))
plt.hist(y_va, bins=60, alpha=0.5, density=True, label="Actual (11ì›”)", color="#6BA3D6")
plt.hist(pred_va, bins=60, alpha=0.5, density=True, label="Pred (11ì›”)", color="#F3C969")
plt.title("ğŸ“ˆ 11ì›” ì „ê¸°ìš”ê¸ˆ ë¶„í¬ (Actual vs Pred)")
plt.xlabel("ì „ê¸°ìš”ê¸ˆ(ì›)")
plt.ylabel("Density")
plt.legend()
plt.tight_layout()
plt.show()

# -----------------------------
# 7) Test(12ì›”) ì˜ˆì¸¡
# -----------------------------
lgb_full = LGBMRegressor(**LGB_PARAMS)
xgb_full = XGBRegressor(**XGB_PARAMS)
cat_full = CatBoostRegressor(**CAT_PARAMS)

lgb_full.fit(X_all, y_all_log)
xgb_full.fit(X_all, y_all_log)
cat_full.fit(X_all, y_all_log)

X_te = test[feat_s2].copy()
pred_te = (
    0.5 * np.expm1(lgb_full.predict(X_te))
    + 0.3 * np.expm1(xgb_full.predict(X_te))
    + 0.2 * np.expm1(cat_full.predict(X_te))
)

low, high = np.percentile(pred_te, [0.2, 99.8])
pred_te = np.clip(pred_te, low, high)

submission = pd.DataFrame({"id": test["id"], "target": pred_te})
submission.to_csv("submission_advanced_v1.csv", index=False)
print("\nğŸ’¾ submission_advanced_v1.csv ì €ì¥ ì™„ë£Œ!")

# Test ì„¸íŠ¸ ì—­ë¥  ìœ„í—˜ ë¶„í¬ í™•ì¸
print("\nğŸ“Š Test(12ì›”) ì—­ë¥  ìœ„í—˜ ë¶„í¬:")
print(f"ë²•ì í˜ë„í‹° ì˜ˆìƒ: {test['ë²•ì í˜ë„í‹°'].sum()}ê±´ ({test['ë²•ì í˜ë„í‹°'].mean()*100:.1f}%)")
print(f"ì‹¤ì§ˆìœ„í—˜ ì˜ˆìƒ: {test['ì‹¤ì§ˆìœ„í—˜'].sum()}ê±´ ({test['ì‹¤ì§ˆìœ„í—˜'].mean()*100:.1f}%)")
print(f"ê·¹ì €ì—­ë¥  ì˜ˆìƒ: {test['ê·¹ì €ì—­ë¥ '].sum()}ê±´ ({test['ê·¹ì €ì—­ë¥ '].mean()*100:.1f}%)")
print(f"ê°€ì„ìœ„í—˜ ì˜ˆìƒ: {test['ê°€ì„ìœ„í—˜'].sum()}ê±´ ({test['ê°€ì„ìœ„í—˜'].mean()*100:.1f}%)")
print(f"ì „ë ¥ê¸‰ë“± ì˜ˆìƒ: {test['ì „ë ¥ê¸‰ë“±'].sum()}ê±´ ({test['ì „ë ¥ê¸‰ë“±'].mean()*100:.1f}%)")



#####################################
# -----------------------------
# 8) ìƒì„¸ ë¶„ì„: Feature Importance & 11ì›” ì„±ëŠ¥
# -----------------------------

# === Feature Importance ìƒì„¸ ë¶„ì„ ===
print("\n" + "="*70)
print("ğŸ” FEATURE IMPORTANCE ë¶„ì„ (LightGBM ê¸°ì¤€)")
print("="*70)

feat_imp = pd.DataFrame({
    'feature': feat_s2,
    'importance': lgb.feature_importances_
}).sort_values('importance', ascending=False)

print("\nğŸ” Top 20 ì¤‘ìš” í”¼ì²˜:")
print(feat_imp.head(20).to_string(index=False))

# ì¹´í…Œê³ ë¦¬ë³„ ì¤‘ìš”ë„ í•©ê³„
print("\nğŸ“Š ì¹´í…Œê³ ë¦¬ë³„ ì¤‘ìš”ë„:")

# EDA ê¸°ë°˜ ì—­ë¥  í”¼ì²˜
eda_features = ['ì§€ìƒì—­ë¥ _ë³´ì •', 'ì£¼ê°„ì—¬ë¶€', 'ë²•ì í˜ë„í‹°', 'ì‹¤ì§ˆìœ„í—˜', 'ê·¹ì €ì—­ë¥ ', 'ì—­ë¥ ë¶€ì¡±í­_94']
eda_imp = feat_imp[feat_imp['feature'].isin(eda_features)]['importance'].sum()
print(f"EDA ì—­ë¥  í”¼ì²˜: {eda_imp:.1f}")

# ê³ ê¸‰ í”¼ì²˜ (1,2,3)
advanced_features = [
    'ë¬´íš¨ìœ íš¨ë¹„ìœ¨', 'ë¶€í•˜ì—­ë¥ ê³±', 'ì—­ë¥ ë‹¹ì „ë ¥',  # 1. ì „ë ¥Ã—ì—­ë¥ 
    'ê°€ì„ìœ„í—˜', 'ë™ì ˆê¸°ì•ˆì •', 'ì—­ë¥ _ì›”í‰ê· ', 'ì—­ë¥ _ì›”í‰ê· ì°¨ì´',  # 2. ê³„ì ˆÃ—ì—­ë¥ 
    'kwh_roll24_cv', 'kwh_ë³€í™”ìœ¨_24h', 'ì „ë ¥ê¸‰ë“±'  # 3. ë¶€í•˜ ë³€ë™ì„±
]
advanced_imp = feat_imp[feat_imp['feature'].isin(advanced_features)]['importance'].sum()
print(f"ê³ ê¸‰ í”¼ì²˜ (1,2,3): {advanced_imp:.1f}")

# Lag/Rolling
lag_features = [f for f in feat_s2 if 'lag' in f or 'roll' in f]
lag_imp = feat_imp[feat_imp['feature'].isin(lag_features)]['importance'].sum()
print(f"Lag/Rolling í”¼ì²˜: {lag_imp:.1f}")

# ê¸°ë³¸ ì‹œê°„ í”¼ì²˜
time_features = ['ì›”', 'ì¼', 'ìš”ì¼', 'ì‹œê°„', 'ì£¼ë§ì—¬ë¶€', 'ê²¨ìš¸ì—¬ë¶€', 'sin_time', 'cos_time']
time_imp = feat_imp[feat_imp['feature'].isin(time_features)]['importance'].sum()
print(f"ì‹œê°„ í”¼ì²˜: {time_imp:.1f}")

# Stage1 ì˜ˆì¸¡ì¹˜
stage1_features = ['ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)', 'ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)', 'ì§„ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)', 
                   'ì§€ìƒì—­ë¥ (%)', 'ì§„ìƒì—­ë¥ (%)', 'ìœ íš¨ì—­ë¥ (%)']
stage1_imp = feat_imp[feat_imp['feature'].isin(stage1_features)]['importance'].sum()
print(f"Stage1 ì˜ˆì¸¡ì¹˜: {stage1_imp:.1f}")

# === ê³ ê¸‰ í”¼ì²˜ë³„ ìƒì„¸ ë¶„ì„ ===
print("\n" + "="*70)
print("ğŸ¯ ê³ ê¸‰ í”¼ì²˜ (1,2,3) ìƒì„¸ ìˆœìœ„")
print("="*70)

advanced_imp_detail = feat_imp[feat_imp['feature'].isin(advanced_features)].copy()
advanced_imp_detail['category'] = advanced_imp_detail['feature'].apply(
    lambda x: '1.ì „ë ¥Ã—ì—­ë¥ ' if x in ['ë¬´íš¨ìœ íš¨ë¹„ìœ¨', 'ë¶€í•˜ì—­ë¥ ê³±', 'ì—­ë¥ ë‹¹ì „ë ¥']
    else '2.ê³„ì ˆÃ—ì—­ë¥ ' if x in ['ê°€ì„ìœ„í—˜', 'ë™ì ˆê¸°ì•ˆì •', 'ì—­ë¥ _ì›”í‰ê· ', 'ì—­ë¥ _ì›”í‰ê· ì°¨ì´']
    else '3.ë¶€í•˜ë³€ë™ì„±'
)
print(advanced_imp_detail.to_string(index=False))

# === 11ì›” ì„±ëŠ¥ ìƒì„¸ ë¶„ì„ ===
print("\n" + "="*70)
print("ğŸ“Š 11ì›” ê²€ì¦ ì„±ëŠ¥ ìƒì„¸ ë¶„ì„")
print("="*70)

mae = mean_absolute_error(y_va, pred_va)
r2 = r2_score(y_va, pred_va)
mape = np.mean(np.abs((y_va - pred_va) / y_va)) * 100
rmse = np.sqrt(np.mean((y_va - pred_va) ** 2))

print(f"\nì „ì²´ ì„±ëŠ¥:")
print(f"  MAE  : {mae:.2f}ì›")
print(f"  RMSE : {rmse:.2f}ì›")
print(f"  RÂ²   : {r2:.4f}")
print(f"  MAPE : {mape:.2f}%")

# ìš”ê¸ˆ êµ¬ê°„ë³„ ì„±ëŠ¥
print(f"\nìš”ê¸ˆ êµ¬ê°„ë³„ MAE:")
y_va_series = pd.Series(y_va.values, index=y_va.index)
pred_va_series = pd.Series(pred_va, index=y_va.index)

bins = [0, 1000, 3000, 5000, 10000, np.inf]
labels = ['0-1k', '1k-3k', '3k-5k', '5k-10k', '10k+']
y_va_binned = pd.cut(y_va_series, bins=bins, labels=labels)

for label in labels:
    mask = (y_va_binned == label)
    if mask.sum() > 0:
        mae_bin = mean_absolute_error(y_va_series[mask], pred_va_series[mask])
        count = mask.sum()
        print(f"  {label:8s}: MAE={mae_bin:7.2f}ì› (n={count:4d})")

# ì—­ë¥  ìœ„í—˜ êµ¬ê°„ë³„ ì„±ëŠ¥ (EDA ì¸ì‚¬ì´íŠ¸ ê²€ì¦!)
print(f"\nì—­ë¥  ìœ„í—˜ êµ¬ê°„ë³„ MAE:")
va_data = train[train["ì›”"] == 11].copy()
va_data["pred"] = pred_va_series.values

# ì‹¤ì§ˆìœ„í—˜ ì—¬ë¶€
for risk_val in [0, 1]:
    mask = (va_data["ì‹¤ì§ˆìœ„í—˜"] == risk_val)
    if mask.sum() > 0:
        mae_risk = mean_absolute_error(
            va_data.loc[mask, "ì „ê¸°ìš”ê¸ˆ(ì›)"], 
            va_data.loc[mask, "pred"]
        )
        count = mask.sum()
        risk_label = "94% ë¯¸ë§Œ" if risk_val == 1 else "94% ì´ìƒ"
        print(f"  {risk_label:10s}: MAE={mae_risk:7.2f}ì› (n={count:4d})")

# ì£¼ê°„/ì•¼ê°„ë³„ ì„±ëŠ¥
print(f"\nì£¼ê°„/ì•¼ê°„ë³„ MAE:")
for period_val in [0, 1]:
    mask = (va_data["ì£¼ê°„ì—¬ë¶€"] == period_val)
    if mask.sum() > 0:
        mae_period = mean_absolute_error(
            va_data.loc[mask, "ì „ê¸°ìš”ê¸ˆ(ì›)"], 
            va_data.loc[mask, "pred"]
        )
        count = mask.sum()
        period_label = "ì£¼ê°„" if period_val == 1 else "ì•¼ê°„"
        print(f"  {period_label:6s}: MAE={mae_period:7.2f}ì› (n={count:4d})")

# ì”ì°¨ ë¶„ì„
residuals = y_va - pred_va
print(f"\nì”ì°¨ ë¶„ì„:")
print(f"  í‰ê·  ì”ì°¨    : {residuals.mean():7.2f}ì›")
print(f"  ì”ì°¨ í‘œì¤€í¸ì°¨: {residuals.std():7.2f}ì›")
print(f"  ìµœëŒ€ ê³¼ëŒ€ì˜ˆì¸¡: {residuals.min():7.2f}ì›")
print(f"  ìµœëŒ€ ê³¼ì†Œì˜ˆì¸¡: {residuals.max():7.2f}ì›")

# ê³¼ëŒ€/ê³¼ì†Œ ì˜ˆì¸¡ ë¹„ìœ¨
over_predict = (residuals < 0).sum()
under_predict = (residuals > 0).sum()
print(f"  ê³¼ëŒ€ì˜ˆì¸¡ ë¹„ìœ¨: {over_predict/len(residuals)*100:.1f}% ({over_predict}ê±´)")
print(f"  ê³¼ì†Œì˜ˆì¸¡ ë¹„ìœ¨: {under_predict/len(residuals)*100:.1f}% ({under_predict}ê±´)")

# === ì‹œê°í™”: ì”ì°¨ ë¶„í¬ ===
fig, axes = plt.subplots(1, 3, figsize=(15, 4))

# 1. ì‹¤ì œ vs ì˜ˆì¸¡ ì‚°ì ë„
axes[0].scatter(y_va, pred_va, alpha=0.3, s=10)
axes[0].plot([y_va.min(), y_va.max()], [y_va.min(), y_va.max()], 'r--', lw=2)
axes[0].set_xlabel('ì‹¤ì œ ìš”ê¸ˆ (ì›)')
axes[0].set_ylabel('ì˜ˆì¸¡ ìš”ê¸ˆ (ì›)')
axes[0].set_title(f'ì‹¤ì œ vs ì˜ˆì¸¡\n(RÂ²={r2:.4f})')
axes[0].grid(alpha=0.3)

# 2. ì”ì°¨ ë¶„í¬
axes[1].hist(residuals, bins=50, alpha=0.7, color='steelblue', edgecolor='black')
axes[1].axvline(x=0, color='red', linestyle='--', linewidth=2)
axes[1].set_xlabel('ì”ì°¨ (ì‹¤ì œ - ì˜ˆì¸¡)')
axes[1].set_ylabel('ë¹ˆë„')
axes[1].set_title(f'ì”ì°¨ ë¶„í¬\n(í‰ê· ={residuals.mean():.1f}ì›)')
axes[1].grid(alpha=0.3)

# 3. ì”ì°¨ vs ì‹¤ì œ ìš”ê¸ˆ
axes[2].scatter(y_va, residuals, alpha=0.3, s=10, color='coral')
axes[2].axhline(y=0, color='red', linestyle='--', linewidth=2)
axes[2].set_xlabel('ì‹¤ì œ ìš”ê¸ˆ (ì›)')
axes[2].set_ylabel('ì”ì°¨ (ì›)')
axes[2].set_title('ì”ì°¨ íŒ¨í„´ ë¶„ì„')
axes[2].grid(alpha=0.3)

plt.tight_layout()
plt.savefig('validation_analysis.png', dpi=150, bbox_inches='tight')
print("\nğŸ’¾ validation_analysis.png ì €ì¥ ì™„ë£Œ!")
plt.show()

# === Feature Importance ì‹œê°í™” ===
fig, ax = plt.subplots(figsize=(10, 8))
top_n = 25
feat_imp_top = feat_imp.head(top_n)

colors = []
for feat in feat_imp_top['feature']:
    if feat in advanced_features:
        if feat in ['ë¬´íš¨ìœ íš¨ë¹„ìœ¨', 'ë¶€í•˜ì—­ë¥ ê³±', 'ì—­ë¥ ë‹¹ì „ë ¥']:
            colors.append('#FF6B6B')  # ë¹¨ê°•: ì „ë ¥Ã—ì—­ë¥ 
        elif feat in ['ê°€ì„ìœ„í—˜', 'ë™ì ˆê¸°ì•ˆì •', 'ì—­ë¥ _ì›”í‰ê· ', 'ì—­ë¥ _ì›”í‰ê· ì°¨ì´']:
            colors.append('#4ECDC4')  # ì²­ë¡: ê³„ì ˆÃ—ì—­ë¥ 
        else:
            colors.append('#FFE66D')  # ë…¸ë‘: ë¶€í•˜ë³€ë™ì„±
    elif feat in eda_features:
        colors.append('#95E1D3')  # ì—°ë‘: EDA ì—­ë¥ 
    else:
        colors.append('#C7CEEA')  # íšŒìƒ‰: ê¸°íƒ€

ax.barh(range(top_n), feat_imp_top['importance'], color=colors, edgecolor='black', linewidth=0.5)
ax.set_yticks(range(top_n))
ax.set_yticklabels(feat_imp_top['feature'], fontsize=9)
ax.set_xlabel('Importance', fontsize=11)
ax.set_title(f'Top {top_n} Feature Importance (LightGBM)', fontsize=13, fontweight='bold')
ax.invert_yaxis()
ax.grid(axis='x', alpha=0.3)

# ë²”ë¡€
from matplotlib.patches import Patch
legend_elements = [
    Patch(facecolor='#FF6B6B', label='1.ì „ë ¥Ã—ì—­ë¥ '),
    Patch(facecolor='#4ECDC4', label='2.ê³„ì ˆÃ—ì—­ë¥ '),
    Patch(facecolor='#FFE66D', label='3.ë¶€í•˜ë³€ë™ì„±'),
    Patch(facecolor='#95E1D3', label='EDA ì—­ë¥ '),
    Patch(facecolor='#C7CEEA', label='ê¸°íƒ€')
]
ax.legend(handles=legend_elements, loc='lower right', fontsize=9)

plt.tight_layout()
plt.savefig('feature_importance_analysis.png', dpi=150, bbox_inches='tight')
print("ğŸ’¾ feature_importance_analysis.png ì €ì¥ ì™„ë£Œ!")
plt.show()

print("\n" + "="*70)
print("âœ… ë¶„ì„ ì™„ë£Œ!")
print("="*70)