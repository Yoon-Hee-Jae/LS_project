import warnings
from pathlib import Path

import numpy as np
import pandas as pd
from catboost import CatBoostRegressor
from lightgbm import LGBMRegressor
from sklearn.linear_model import Ridge
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.model_selection import TimeSeriesSplit
from sklearn.preprocessing import LabelEncoder
from xgboost import XGBRegressor

warnings.filterwarnings("ignore")

# ---------------------------------------------------------------------------
# 0) Load
# ---------------------------------------------------------------------------
BASE_DIR = Path(__file__).resolve().parent
DATA_DIR = BASE_DIR / "data"

train = pd.read_csv(DATA_DIR / "train_.csv")
test = pd.read_csv(DATA_DIR / "test_.csv")


# ---------------------------------------------------------------------------
# 1) Time Features & Encoding
# ---------------------------------------------------------------------------
REF_DATE = pd.Timestamp("2024-10-24")


def adjust_hour(dt: pd.Timestamp) -> float:
    if pd.isna(dt):
        return np.nan
    return dt.hour if dt.minute >= 15 else (dt.hour - 1) % 24


def band_of_hour(hour: float) -> str:
    if pd.isna(hour):
        return "unknown"
    if (22 <= hour <= 23) or (0 <= hour <= 7):
        return "ê²½ë¶€í•˜"
    if 16 <= hour <= 21:
        return "ìµœëŒ€ë¶€í•˜"
    return "ì¤‘ê°„ë¶€í•˜"


def enrich_time(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df["ì¸¡ì •ì¼ì‹œ"] = pd.to_datetime(df["ì¸¡ì •ì¼ì‹œ"], errors="coerce")
    df["ì›”"] = df["ì¸¡ì •ì¼ì‹œ"].dt.month
    df["ì¼"] = df["ì¸¡ì •ì¼ì‹œ"].dt.day
    df["ìš”ì¼"] = df["ì¸¡ì •ì¼ì‹œ"].dt.dayofweek
    df["ì‹œê°„"] = df["ì¸¡ì •ì¼ì‹œ"].apply(adjust_hour)
    df["ì£¼ë§ì—¬ë¶€"] = (df["ìš”ì¼"] >= 5).astype(int)
    df["ê²¨ìš¸ì—¬ë¶€"] = df["ì›”"].isin([11, 12, 1, 2]).astype(int)
    df["period_flag"] = (df["ì¸¡ì •ì¼ì‹œ"] >= REF_DATE).astype(int)
    df["sin_time"] = np.sin(2 * np.pi * df["ì‹œê°„"] / 24)
    df["cos_time"] = np.cos(2 * np.pi * df["ì‹œê°„"] / 24)
    df["sin_day"] = np.sin(2 * np.pi * df["ì¼"] / 31)
    df["cos_day"] = np.cos(2 * np.pi * df["ì¼"] / 31)
    df["sin_month"] = np.sin(2 * np.pi * df["ì›”"] / 12)
    df["cos_month"] = np.cos(2 * np.pi * df["ì›”"] / 12)
    df["ë¶€í•˜êµ¬ë¶„"] = df["ì‹œê°„"].apply(band_of_hour)
    return df


train = enrich_time(train).sort_values("ì¸¡ì •ì¼ì‹œ").reset_index(drop=True)
test = enrich_time(test).sort_values("ì¸¡ì •ì¼ì‹œ").reset_index(drop=True)

job_encoder = LabelEncoder()
train["ì‘ì—…ìœ í˜•_encoded"] = job_encoder.fit_transform(train["ì‘ì—…ìœ í˜•"].astype(str))
test["ì‘ì—…ìœ í˜•_encoded"] = job_encoder.transform(test["ì‘ì—…ìœ í˜•"].astype(str))

band_encoder = LabelEncoder()
train["ë¶€í•˜êµ¬ë¶„_encoded"] = band_encoder.fit_transform(train["ë¶€í•˜êµ¬ë¶„"].astype(str))
test["ë¶€í•˜êµ¬ë¶„_encoded"] = band_encoder.transform(test["ë¶€í•˜êµ¬ë¶„"].astype(str))

train["ì‹œê°„_ì‘ì—…ìœ í˜•"] = train["ì‹œê°„"].astype(str) + "_" + train["ì‘ì—…ìœ í˜•_encoded"].astype(str)
test["ì‹œê°„_ì‘ì—…ìœ í˜•"] = test["ì‹œê°„"].astype(str) + "_" + test["ì‘ì—…ìœ í˜•_encoded"].astype(str)

combo_encoder = LabelEncoder()
train["ì‹œê°„_ì‘ì—…ìœ í˜•_encoded"] = combo_encoder.fit_transform(train["ì‹œê°„_ì‘ì—…ìœ í˜•"])
test["ì‹œê°„_ì‘ì—…ìœ í˜•_encoded"] = combo_encoder.transform(test["ì‹œê°„_ì‘ì—…ìœ í˜•"])


# ---------------------------------------------------------------------------
# 2) Stage1 Models (OOF)
# ---------------------------------------------------------------------------
targets_stage1 = [
    "ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)",
    "ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)",
    "ì§„ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)",
    "ì§€ìƒì—­ë¥ (%)",
    "ì§„ìƒì—­ë¥ (%)",
]

features_stage1 = [
    "ì›”",
    "ì¼",
    "ìš”ì¼",
    "ì‹œê°„",
    "ì£¼ë§ì—¬ë¶€",
    "ê²¨ìš¸ì—¬ë¶€",
    "period_flag",
    "sin_time",
    "cos_time",
    "sin_day",
    "cos_day",
    "sin_month",
    "cos_month",
    "ì‘ì—…ìœ í˜•_encoded",
    "ë¶€í•˜êµ¬ë¶„_encoded",
    "ì‹œê°„_ì‘ì—…ìœ í˜•_encoded",
]

stage1_models = {
    "ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)": LGBMRegressor(
        n_estimators=3500,
        learning_rate=0.01,
        num_leaves=128,
        subsample=0.85,
        colsample_bytree=0.85,
        random_state=42,
        n_jobs=-1,
    ),
    "ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)": CatBoostRegressor(
        iterations=3200,
        learning_rate=0.02,
        depth=8,
        verbose=0,
        random_seed=42,
        thread_count=-1,
    ),
    "ì§„ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)": CatBoostRegressor(
        iterations=3200,
        learning_rate=0.02,
        depth=8,
        verbose=0,
        random_seed=42,
        thread_count=-1,
    ),
    "ì§€ìƒì—­ë¥ (%)": LGBMRegressor(
        n_estimators=3200,
        learning_rate=0.012,
        num_leaves=96,
        random_state=42,
        n_jobs=-1,
    ),
    "ì§„ìƒì—­ë¥ (%)": LGBMRegressor(
        n_estimators=3200,
        learning_rate=0.012,
        num_leaves=96,
        random_state=42,
        n_jobs=-1,
    ),
}

tscv_stage1 = TimeSeriesSplit(n_splits=5)
stage1_oof = pd.DataFrame(index=train.index, columns=targets_stage1)
stage1_test = pd.DataFrame(index=test.index, columns=targets_stage1)

for target in targets_stage1:
    model = stage1_models[target]
    oof_pred = np.full(len(train), np.nan)
    test_fold_sum = np.zeros(len(test), dtype=float)

    for fold, (idx_tr, idx_va) in enumerate(tscv_stage1.split(train), start=1):
        X_tr = train.iloc[idx_tr][features_stage1]
        y_tr = train.iloc[idx_tr][target]
        X_va = train.iloc[idx_va][features_stage1]

        model_fold = model.__class__(**model.get_params())
        model_fold.fit(X_tr, y_tr)
        oof_pred[idx_va] = model_fold.predict(X_va)
        test_fold_sum += model_fold.predict(test[features_stage1])

    stage1_oof[target] = oof_pred
    stage1_test[target] = test_fold_sum / tscv_stage1.get_n_splits()

    # ì´ˆê¸° êµ¬ê°„ ë³´ì • (shiftë¡œ ì¸í•œ NaN)
    nan_mask = stage1_oof[target].isna()
    if nan_mask.any():
        filler = model.__class__(**model.get_params())
        filler.fit(train[features_stage1], train[target])
        stage1_oof.loc[nan_mask, target] = filler.predict(train.loc[nan_mask, features_stage1])

# Stage1 ì˜ˆì¸¡ê°’ìœ¼ë¡œ ëŒ€ì²´ (true ê°’ì€ ë³´ì¡´)
for tgt in targets_stage1:
    train[f"{tgt}_true"] = train[tgt]
    train[tgt] = stage1_oof[tgt]
    test[tgt] = stage1_test[tgt]


# ---------------------------------------------------------------------------
# 3) Stage1 Derived Features
# ---------------------------------------------------------------------------
def add_pf_features(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df["ìœ íš¨ì—­ë¥ (%)"] = df[["ì§€ìƒì—­ë¥ (%)", "ì§„ìƒì—­ë¥ (%)"]].max(axis=1)
    df["ì—­ë¥ ë¶€ì¡±í­_90"] = (90 - df["ì§€ìƒì—­ë¥ (%)"]).clip(lower=0)
    df["ì—­ë¥ ë¶€ì¡±í­_94"] = (94 - df["ì§€ìƒì—­ë¥ (%)"]).clip(lower=0)
    df["ì—­ë¥ ìš°ìˆ˜"] = (df["ì§€ìƒì—­ë¥ (%)"] >= 95).astype(int)

    df["ì£¼ê°„ì—¬ë¶€"] = df["ì‹œê°„"].between(9, 22).astype(int)
    df["ë²•ì í˜ë„í‹°"] = ((df["ì£¼ê°„ì—¬ë¶€"] == 1) & (df["ì§€ìƒì—­ë¥ (%)"] < 90)).astype(int)
    df["ì‹¤ì§ˆìœ„í—˜"] = ((df["ì£¼ê°„ì—¬ë¶€"] == 1) & (df["ì§€ìƒì—­ë¥ (%)"] < 94)).astype(int)
    df["ê·¹ì €ì—­ë¥ "] = ((df["ì£¼ê°„ì—¬ë¶€"] == 1) & (df["ì§€ìƒì—­ë¥ (%)"] < 85)).astype(int)

    df["ì£¼ê°„_ë¶€ì¡±ë¥ "] = df["ì£¼ê°„ì—¬ë¶€"] * (90 - df["ì§€ìƒì—­ë¥ (%)"]).clip(lower=0)
    df["ì£¼ê°„_ì¶”ê°€ìš”ìœ¨"] = df["ì£¼ê°„_ë¶€ì¡±ë¥ "] * 0.01

    df["ë¶€í•˜ì—­ë¥ ê³±_ê°•í™”"] = (
        df["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"] * df["ì—­ë¥ ë¶€ì¡±í­_94"] * df["ì£¼ê°„ì—¬ë¶€"] * 10
    )
    df["ì—­ë¥ ë¶€ì¡±_ê²½ë¶€í•˜"] = (df["ë¶€í•˜êµ¬ë¶„"] == "ê²½ë¶€í•˜").astype(int) * df["ì—­ë¥ ë¶€ì¡±í­_94"]
    df["ì—­ë¥ ë¶€ì¡±_ì¤‘ê°„ë¶€í•˜"] = (df["ë¶€í•˜êµ¬ë¶„"] == "ì¤‘ê°„ë¶€í•˜").astype(int) * df["ì—­ë¥ ë¶€ì¡±í­_94"]
    df["ì—­ë¥ ë¶€ì¡±_ìµœëŒ€ë¶€í•˜"] = (df["ë¶€í•˜êµ¬ë¶„"] == "ìµœëŒ€ë¶€í•˜").astype(int) * df["ì—­ë¥ ë¶€ì¡±í­_94"]

    df["ì—­ë¥ _60_85"] = (
        (df["ì§€ìƒì—­ë¥ (%)"].between(60, 85, inclusive="left")) & (df["ì£¼ê°„ì—¬ë¶€"] == 1)
    ).astype(int)
    df["ì—­ë¥ _85_90"] = (
        (df["ì§€ìƒì—­ë¥ (%)"].between(85, 90, inclusive="left")) & (df["ì£¼ê°„ì—¬ë¶€"] == 1)
    ).astype(int)
    df["ì—­ë¥ _90_94"] = (
        (df["ì§€ìƒì—­ë¥ (%)"].between(90, 94, inclusive="left")) & (df["ì£¼ê°„ì—¬ë¶€"] == 1)
    ).astype(int)
    df["ì—­ë¥ _94_ì´ìƒ"] = ((df["ì§€ìƒì—­ë¥ (%)"] >= 94) & (df["ì£¼ê°„ì—¬ë¶€"] == 1)).astype(int)
    return df


train = add_pf_features(train)
test = add_pf_features(test)


# ---------------------------------------------------------------------------
# 4) Lag / Rolling Features
# ---------------------------------------------------------------------------
def add_lag_features(df_train: pd.DataFrame, df_test: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame]:
    train_aug = df_train.copy()
    test_aug = df_test.copy()

    # Train lag/rolling
    train_aug["kwh_lag1"] = train_aug["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"].shift(1)
    train_aug["kwh_lag24"] = train_aug["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"].shift(24)
    train_aug["kwh_lag96"] = train_aug["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"].shift(96)
    train_aug["kwh_lag168"] = train_aug["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"].shift(168)
    train_aug["kwh_lag672"] = train_aug["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"].shift(672)

    for window in [12, 24, 48, 96]:
        roll_mean = train_aug["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"].shift(1).rolling(window).mean()
        roll_std = train_aug["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"].shift(1).rolling(window).std().fillna(0)
        train_aug[f"kwh_roll{window}_mean"] = roll_mean
        train_aug[f"kwh_roll{window}_std"] = roll_std
        train_aug[f"kwh_roll{window}_cv"] = roll_std / (roll_mean + 1e-6)

    train_aug["kwh_roll24_range"] = (
        train_aug["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"].shift(1).rolling(24).max()
        - train_aug["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"].shift(1).rolling(24).min()
    )
    train_aug["kwh_lag24_ratio"] = train_aug["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"] / (train_aug["kwh_lag24"] + 1e-6)
    train_aug["kwh_roll24_ratio"] = train_aug["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"] / (train_aug["kwh_roll24_mean"] + 1e-6)
    train_aug["kwh_lag168_ratio"] = train_aug["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"] / (train_aug["kwh_lag168"] + 1e-6)
    train_aug["kwh_vs_ì–´ì œ"] = (train_aug["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"] - train_aug["kwh_lag24"]) / (
        train_aug["kwh_lag24"] + 1e-6
    )
    train_aug["ì „ë ¥ê¸‰ë“±"] = (train_aug["kwh_vs_ì–´ì œ"] > 0.5).astype(int)
    train_aug["ìœ„í—˜_ë³€ë™ì„±"] = train_aug["ì‹¤ì§ˆìœ„í—˜"] * train_aug["kwh_roll24_cv"]

    # kVarh lags/rolling
    train_aug["kvarh_lag1"] = train_aug["ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)"].shift(1)
    train_aug["kvarh_roll24_mean"] = train_aug["ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)"].shift(1).rolling(24).mean()
    train_aug["kvarh_roll96_mean"] = train_aug["ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)"].shift(1).rolling(96).mean()

    # Recursive generation for test
    hist_kwh = list(train_aug["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"].tail(672).values.astype(float))
    hist_kvarh = list(train_aug["ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)"].tail(672).values.astype(float))

    kwh_features = {name: [] for name in [
        "kwh_lag1", "kwh_lag24", "kwh_lag96", "kwh_lag168", "kwh_lag672",
        "kwh_roll12_mean", "kwh_roll12_std", "kwh_roll12_cv",
        "kwh_roll24_mean", "kwh_roll24_std", "kwh_roll24_cv",
        "kwh_roll48_mean", "kwh_roll48_std", "kwh_roll48_cv",
        "kwh_roll96_mean", "kwh_roll96_std", "kwh_roll96_cv",
        "kwh_roll24_range", "kwh_lag24_ratio", "kwh_roll24_ratio",
        "kwh_lag168_ratio", "kwh_vs_ì–´ì œ"
    ]}
    kvarh_features = {name: [] for name in ["kvarh_lag1", "kvarh_roll24_mean", "kvarh_roll96_mean"]}

    for _, row in test_aug.iterrows():
        kwh_vals = np.array(hist_kwh)
        kwh_lag1 = kwh_vals[-1] if kwh_vals.size >= 1 else np.nan
        kwh_lag24 = kwh_vals[-24] if kwh_vals.size >= 24 else np.nan
        kwh_lag96 = kwh_vals[-96] if kwh_vals.size >= 96 else np.nan
        kwh_lag168 = kwh_vals[-168] if kwh_vals.size >= 168 else np.nan
        kwh_lag672 = kwh_vals[-672] if kwh_vals.size >= 672 else np.nan

        def recent(arr, window):
            return arr[-window:] if arr.size >= window else arr

        arr12 = recent(kwh_vals, 12)
        arr24 = recent(kwh_vals, 24)
        arr48 = recent(kwh_vals, 48)
        arr96 = recent(kwh_vals, 96)

        roll_means = {
            12: arr12.mean() if arr12.size else np.nan,
            24: arr24.mean() if arr24.size else np.nan,
            48: arr48.mean() if arr48.size else np.nan,
            96: arr96.mean() if arr96.size else np.nan,
        }
        roll_stds = {
            12: arr12.std() if arr12.size > 1 else 0,
            24: arr24.std() if arr24.size > 1 else 0,
            48: arr48.std() if arr48.size > 1 else 0,
            96: arr96.std() if arr96.size > 1 else 0,
        }

        kwh_features["kwh_lag1"].append(kwh_lag1)
        kwh_features["kwh_lag24"].append(kwh_lag24)
        kwh_features["kwh_lag96"].append(kwh_lag96)
        kwh_features["kwh_lag168"].append(kwh_lag168)
        kwh_features["kwh_lag672"].append(kwh_lag672)
        kwh_features["kwh_roll12_mean"].append(roll_means[12])
        kwh_features["kwh_roll24_mean"].append(roll_means[24])
        kwh_features["kwh_roll48_mean"].append(roll_means[48])
        kwh_features["kwh_roll96_mean"].append(roll_means[96])
        kwh_features["kwh_roll12_std"].append(roll_stds[12])
        kwh_features["kwh_roll24_std"].append(roll_stds[24])
        kwh_features["kwh_roll48_std"].append(roll_stds[48])
        kwh_features["kwh_roll96_std"].append(roll_stds[96])
        kwh_features["kwh_roll12_cv"].append(roll_stds[12] / (roll_means[12] + 1e-6) if not np.isnan(roll_means[12]) else np.nan)
        kwh_features["kwh_roll24_cv"].append(roll_stds[24] / (roll_means[24] + 1e-6) if not np.isnan(roll_means[24]) else np.nan)
        kwh_features["kwh_roll48_cv"].append(roll_stds[48] / (roll_means[48] + 1e-6) if not np.isnan(roll_means[48]) else np.nan)
        kwh_features["kwh_roll96_cv"].append(roll_stds[96] / (roll_means[96] + 1e-6) if not np.isnan(roll_means[96]) else np.nan)
        kwh_features["kwh_roll24_range"].append(
            arr24.max() - arr24.min() if arr24.size else np.nan
        )
        kwh_features["kwh_lag24_ratio"].append(
            row["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"] / (kwh_lag24 + 1e-6) if not np.isnan(kwh_lag24) else np.nan
        )
        kwh_features["kwh_roll24_ratio"].append(
            row["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"] / (roll_means[24] + 1e-6) if not np.isnan(roll_means[24]) else np.nan
        )
        kwh_features["kwh_lag168_ratio"].append(
            row["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"] / (kwh_lag168 + 1e-6) if not np.isnan(kwh_lag168) else np.nan
        )
        kwh_features["kwh_vs_ì–´ì œ"].append(
            (row["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"] - kwh_lag24) / (kwh_lag24 + 1e-6) if not np.isnan(kwh_lag24) else np.nan
        )

        kvarh_vals = np.array(hist_kvarh)
        kvarh_lag1 = kvarh_vals[-1] if kvarh_vals.size >= 1 else np.nan
        arr24_kvarh = kvarh_vals[-24:] if kvarh_vals.size >= 24 else kvarh_vals
        arr96_kvarh = kvarh_vals[-96:] if kvarh_vals.size >= 96 else kvarh_vals

        kvarh_features["kvarh_lag1"].append(kvarh_lag1)
        kvarh_features["kvarh_roll24_mean"].append(arr24_kvarh.mean() if arr24_kvarh.size else np.nan)
        kvarh_features["kvarh_roll96_mean"].append(arr96_kvarh.mean() if arr96_kvarh.size else np.nan)

        hist_kwh.append(row["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"])
        hist_kvarh.append(row["ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)"])

    for key, values in kwh_features.items():
        test_aug[key] = values
    for key, values in kvarh_features.items():
        test_aug[key] = values

    test_aug["ì „ë ¥ê¸‰ë“±"] = (np.array(kwh_features["kwh_vs_ì–´ì œ"]) > 0.5).astype(int)
    test_aug["ìœ„í—˜_ë³€ë™ì„±"] = test_aug["ì‹¤ì§ˆìœ„í—˜"] * test_aug["kwh_roll24_cv"]

    return train_aug, test_aug


train, test = add_lag_features(train, test)


# ---------------------------------------------------------------------------
# 5) Advanced Aggregations
# ---------------------------------------------------------------------------
mean_day_hour = (
    train.groupby(["ìš”ì¼", "ì‹œê°„"])["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"].mean().rename("kwh_ìš”ì¼_ì‹œê°„_í‰ê· ").reset_index()
)
train = train.merge(mean_day_hour, on=["ìš”ì¼", "ì‹œê°„"], how="left")
test = test.merge(mean_day_hour, on=["ìš”ì¼", "ì‹œê°„"], how="left")


def add_advanced_features(df: pd.DataFrame, is_train: bool) -> pd.DataFrame:
    df = df.copy()
    df["ë¬´íš¨ìœ íš¨ë¹„ìœ¨"] = df["ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)"] / (df["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"] + 1e-6)
    df["ë¶€í•˜ì—­ë¥ ê³±"] = df["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"] * df["ì—­ë¥ ë¶€ì¡±í­_94"]
    df["ì—­ë¥ ë‹¹ì „ë ¥"] = df["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"] / (df["ì§€ìƒì—­ë¥ (%)"] + 1e-6)
    df["ì´ë¬´íš¨ì „ë ¥"] = df["ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)"] + df["ì§„ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)"]
    df["ë¬´íš¨ì „ë ¥ë¹„ì¤‘"] = df["ì´ë¬´íš¨ì „ë ¥"] / (df["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"] + df["ì´ë¬´íš¨ì „ë ¥"] + 1e-6)

    df["ê°€ì„ìœ„í—˜"] = ((df["ì›”"].isin([9, 10])) & (df["ì‹¤ì§ˆìœ„í—˜"] == 1)).astype(int)
    df["ë™ì ˆê¸°ì•ˆì •"] = ((df["ê²¨ìš¸ì—¬ë¶€"] == 1) & (df["ì§€ìƒì—­ë¥ (%)"] >= 94)).astype(int)

    if is_train:
        df["ì—­ë¥ _ì›”í‰ê· "] = df.groupby("ì›”")["ì§€ìƒì—­ë¥ (%)"].transform("mean")
        df["ì „ë ¥ì‚¬ìš©_ì‹œê°„í‰ê· "] = df.groupby("ì‹œê°„")["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"].transform("mean")
    else:
        monthly_mean = train.groupby("ì›”")["ì§€ìƒì—­ë¥ (%)"].mean()
        hourly_mean = train.groupby("ì‹œê°„")["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"].mean()
        df["ì—­ë¥ _ì›”í‰ê· "] = df["ì›”"].map(monthly_mean)
        df["ì „ë ¥ì‚¬ìš©_ì‹œê°„í‰ê· "] = df["ì‹œê°„"].map(hourly_mean)
        df["ì—­ë¥ _ì›”í‰ê· "].fillna(monthly_mean.mean(), inplace=True)
        df["ì „ë ¥ì‚¬ìš©_ì‹œê°„í‰ê· "].fillna(hourly_mean.mean(), inplace=True)

    df["ì—­ë¥ _ì›”í‰ê· ì°¨ì´"] = df["ì§€ìƒì—­ë¥ (%)"] - df["ì—­ë¥ _ì›”í‰ê· "]
    df["ì „ë ¥ì‚¬ìš©_ì‹œê°„ëŒ€ë¹„"] = df["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"] / (df["ì „ë ¥ì‚¬ìš©_ì‹œê°„í‰ê· "] + 1e-6)
    df["kwh_ì‹œê°„ëŒ€ë¹„_ìš”ì¼"] = df["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"] / (df["kwh_ìš”ì¼_ì‹œê°„_í‰ê· "] + 1e-6)
    df.drop(columns="kwh_ìš”ì¼_ì‹œê°„_í‰ê· ", inplace=True)
    return df


train = add_advanced_features(train, is_train=True)
test = add_advanced_features(test, is_train=False)


# ---------------------------------------------------------------------------
# 6) Stage2 Training (Stacking + Bias Correction)
# ---------------------------------------------------------------------------
features_stage2 = [
    # Time / categorical
    "ì›”", "ì¼", "ìš”ì¼", "ì‹œê°„", "ì£¼ë§ì—¬ë¶€", "ê²¨ìš¸ì—¬ë¶€", "period_flag",
    "sin_time", "cos_time", "sin_day", "cos_day", "sin_month", "cos_month",
    "ì‘ì—…ìœ í˜•_encoded", "ë¶€í•˜êµ¬ë¶„_encoded", "ì‹œê°„_ì‘ì—…ìœ í˜•_encoded",
    # Stage1 outputs
    "ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)", "ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)", "ì§„ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)",
    "ì§€ìƒì—­ë¥ (%)", "ì§„ìƒì—­ë¥ (%)", "ìœ íš¨ì—­ë¥ (%)",
    # Lag / rolling
    "kwh_lag1", "kwh_lag24", "kwh_lag96", "kwh_lag168", "kwh_lag672",
    "kwh_roll12_mean", "kwh_roll12_std", "kwh_roll12_cv",
    "kwh_roll24_mean", "kwh_roll24_std", "kwh_roll24_cv",
    "kwh_roll48_mean", "kwh_roll48_std", "kwh_roll48_cv",
    "kwh_roll96_mean", "kwh_roll96_std", "kwh_roll96_cv",
    "kwh_roll24_range",
    "kwh_lag24_ratio", "kwh_roll24_ratio", "kwh_lag168_ratio", "kwh_vs_ì–´ì œ",
    "ì „ë ¥ê¸‰ë“±", "ìœ„í—˜_ë³€ë™ì„±",
    "kvarh_lag1", "kvarh_roll24_mean", "kvarh_roll96_mean",
    # PF features
    "ì—­ë¥ ë¶€ì¡±í­_90", "ì—­ë¥ ë¶€ì¡±í­_94", "ì—­ë¥ ìš°ìˆ˜",
    "ì£¼ê°„ì—¬ë¶€", "ë²•ì í˜ë„í‹°", "ì‹¤ì§ˆìœ„í—˜", "ê·¹ì €ì—­ë¥ ",
    "ì£¼ê°„_ë¶€ì¡±ë¥ ", "ì£¼ê°„_ì¶”ê°€ìš”ìœ¨", "ë¶€í•˜ì—­ë¥ ê³±", "ë¶€í•˜ì—­ë¥ ê³±_ê°•í™”",
    "ì—­ë¥ ë¶€ì¡±_ê²½ë¶€í•˜", "ì—­ë¥ ë¶€ì¡±_ì¤‘ê°„ë¶€í•˜", "ì—­ë¥ ë¶€ì¡±_ìµœëŒ€ë¶€í•˜",
    "ì—­ë¥ _60_85", "ì—­ë¥ _85_90", "ì—­ë¥ _90_94", "ì—­ë¥ _94_ì´ìƒ",
    "ë¬´íš¨ìœ íš¨ë¹„ìœ¨", "ì—­ë¥ ë‹¹ì „ë ¥", "ì´ë¬´íš¨ì „ë ¥", "ë¬´íš¨ì „ë ¥ë¹„ì¤‘",
    "ê°€ì„ìœ„í—˜", "ë™ì ˆê¸°ì•ˆì •",
    "ì—­ë¥ _ì›”í‰ê· ", "ì—­ë¥ _ì›”í‰ê· ì°¨ì´",
    "ì „ë ¥ì‚¬ìš©_ì‹œê°„í‰ê· ", "ì „ë ¥ì‚¬ìš©_ì‹œê°„ëŒ€ë¹„", "kwh_ì‹œê°„ëŒ€ë¹„_ìš”ì¼",
]

X_all = train[features_stage2].copy()
y_all = train["ì „ê¸°ìš”ê¸ˆ(ì›)"].copy()
y_all_log = np.log1p(y_all)

sample_weights = np.ones(len(y_all), dtype=float)
sample_weights[y_all > 3000] = 2.0
sample_weights[y_all > 5000] = 3.0
sample_weights[y_all > 10000] = 5.0
sample_weights[X_all["ì‹¤ì§ˆìœ„í—˜"] == 1] *= 2.0

LGB_PARAMS = dict(
    n_estimators=3500,
    learning_rate=0.012,
    num_leaves=128,
    subsample=0.85,
    colsample_bytree=0.85,
    reg_alpha=3,
    reg_lambda=4,
    min_child_samples=18,
    random_state=42,
    n_jobs=-1,
)
XGB_PARAMS = dict(
    n_estimators=3500,
    learning_rate=0.012,
    max_depth=9,
    subsample=0.8,
    colsample_bytree=0.8,
    reg_lambda=4,
    reg_alpha=2,
    min_child_weight=3,
    random_state=42,
    n_jobs=-1,
)
CAT_PARAMS = dict(
    iterations=3000,
    learning_rate=0.015,
    depth=8,
    l2_leaf_reg=4,
    random_seed=42,
    verbose=0,
    thread_count=-1,
)

base_models = {
    "lgb": LGBMRegressor(**LGB_PARAMS),
    "xgb": XGBRegressor(**XGB_PARAMS),
    "cat": CatBoostRegressor(**CAT_PARAMS),
}

tscv_stage2 = TimeSeriesSplit(n_splits=5)
oof_pred = pd.DataFrame(index=X_all.index, columns=base_models.keys(), dtype=float)

for fold, (idx_tr, idx_va) in enumerate(tscv_stage2.split(X_all), start=1):
    X_tr, X_va = X_all.iloc[idx_tr], X_all.iloc[idx_va]
    y_tr, y_va = y_all_log.iloc[idx_tr], y_all_log.iloc[idx_va]
    w_tr = sample_weights[idx_tr]

    for name, model in base_models.items():
        model_fold = model.__class__(**model.get_params())
        model_fold.fit(X_tr, y_tr, sample_weight=w_tr)
        oof_pred.loc[idx_va, name] = model_fold.predict(X_va)

meta_learner = Ridge(alpha=100)
valid_idx = oof_pred.dropna().index
meta_learner.fit(oof_pred.loc[valid_idx], y_all_log.loc[valid_idx])

# Fit full models
model_lgb = LGBMRegressor(**LGB_PARAMS)
model_xgb = XGBRegressor(**XGB_PARAMS)
model_cat = CatBoostRegressor(**CAT_PARAMS)

model_lgb.fit(X_all, y_all_log, sample_weight=sample_weights)
model_xgb.fit(X_all, y_all_log, sample_weight=sample_weights)
model_cat.fit(X_all, y_all_log, sample_weight=sample_weights)


# ---------------------------------------------------------------------------
# 7) Validation (November) with Bias Buckets
# ---------------------------------------------------------------------------
va_mask = train["ì›”"] == 11
X_va = X_all[va_mask]
y_va = y_all[va_mask]

va_preds = np.expm1(meta_learner.predict(pd.DataFrame({
    "lgb": model_lgb.predict(X_va),
    "xgb": model_xgb.predict(X_va),
    "cat": model_cat.predict(X_va),
}, index=X_va.index)))

mae = mean_absolute_error(y_va, va_preds)
r2 = r2_score(y_va, va_preds)
print(f"\nğŸ“Š 11ì›” ê²€ì¦ (Stacking): MAE={mae:.2f} | RÂ²={r2:.4f}")


# ---------------------------------------------------------------------------
# 8) Test Prediction (December) with Bias Buckets
# ---------------------------------------------------------------------------
X_te = test[features_stage2].copy()

pred_meta = meta_learner.predict(pd.DataFrame({
    "lgb": model_lgb.predict(X_te),
    "xgb": model_xgb.predict(X_te),
    "cat": model_cat.predict(X_te),
}, index=X_te.index))

pred_te = np.expm1(pred_meta)

low, high = np.percentile(pred_te, [0.1, 99.9])
pred_te = np.clip(pred_te, low, high)

submission = pd.DataFrame({"id": test["id"], "target": pred_te})
submission.to_csv(BASE_DIR / "submission_783_biasweighted.csv", index=False)

print("\nğŸ’¾ submission_783_biasweighted.csv ì €ì¥ ì™„ë£Œ!")
print(f"ì˜ˆì¸¡ ë²”ìœ„: {pred_te.min():.2f} ~ {pred_te.max():.2f}")
print(f"ì˜ˆì¸¡ í‰ê· : {pred_te.mean():.2f}")


# ---------------------------------------------------------------------------
# 9) Feature Importance (LightGBM)
# ---------------------------------------------------------------------------
feat_importance = pd.DataFrame({
    "feature": features_stage2,
    "importance": model_lgb.feature_importances_,
}).sort_values("importance", ascending=False)

print("\nğŸ” Top 20 Feature Importance (LGBM):")
print(feat_importance.head(20).to_string(index=False))

# ---------------------------------------------------------------------------
# 10) Full Train Evaluation (January~November)
# ---------------------------------------------------------------------------
stack_inputs_all = pd.DataFrame({
    "lgb": model_lgb.predict(X_all),
    "xgb": model_xgb.predict(X_all),
    "cat": model_cat.predict(X_all),
}, index=X_all.index)
train_preds_all = np.expm1(meta_learner.predict(stack_inputs_all))

monthly_metrics = []
for month in sorted(train["ì›”"].unique()):
    month_mask = train["ì›”"] == month
    y_month = y_all[month_mask]
    pred_month = train_preds_all[month_mask]

    mae_month = mean_absolute_error(y_month, pred_month)
    r2_month = r2_score(y_month, pred_month)
    monthly_metrics.append((month, mae_month, r2_month))
    print(f"ğŸ“… {month}ì›” ê²€ì¦: MAE={mae_month:.2f} | RÂ²={r2_month:.4f}")

best_month, best_mae, best_r2 = min(monthly_metrics, key=lambda x: x[1])
print(f"\nâœ… ì›”ë³„ MAE ìµœì €: {best_month}ì›” (MAE={best_mae:.2f}, RÂ²={best_r2:.4f})")
